{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAFA Dataset Exploration / Visualization\n",
    "\n",
    "# Load the .mat file\n",
    "train_data = scipy.io.loadmat(r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\LabelTrainAll.mat')\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(train_data['label_train'][0])\n",
    "df\n",
    "\n",
    "# Define the path to the images\n",
    "image_path = r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\train-images'\n",
    "\n",
    "# Function to display image with bounding boxes and eye positions\n",
    "def display_image_with_features(row):\n",
    "    # Load the image\n",
    "    img_name = row['imgName'][0]\n",
    "    image = plt.imread(image_path + '\\\\' + img_name)\n",
    "    \n",
    "    # Display the image\n",
    "    plt.imshow(image)\n",
    "    \n",
    "    # Get the face bounding box\n",
    "    face_bbox = row['label'][0][:4]\n",
    "    x, y, w, h = face_bbox\n",
    "    \n",
    "    # Draw face bounding box\n",
    "    plt.gca().add_patch(patches.Rectangle((x, y), w, h, linewidth=2, edgecolor='r', facecolor='none'))\n",
    "    \n",
    "    # Get the bounding box of the occluder\n",
    "    occluder_bbox = row['label'][0][8:12]\n",
    "    if not np.all(occluder_bbox == -1):\n",
    "        ox, oy, ow, oh = occluder_bbox\n",
    "        # Draw occluder bounding box\n",
    "        plt.gca().add_patch(patches.Rectangle((x + ox, y + oy), ow, oh, linewidth=2, edgecolor='b', facecolor='none'))\n",
    "    \n",
    "    # Get the bounding box of the glasses\n",
    "    glasses_bbox = row['label'][0][-4:]\n",
    "    if not np.all(glasses_bbox == -1):\n",
    "        gx, gy, gw, gh = glasses_bbox\n",
    "        # Draw glasses bounding box\n",
    "        plt.gca().add_patch(patches.Rectangle((x + gx, y + gy), gw, gh, linewidth=2, edgecolor='g', facecolor='none'))\n",
    "    \n",
    "    # Get the positions of the eyes (relative to the face bounding box)\n",
    "    eye1_x, eye1_y, eye2_x, eye2_y = row['label'][0][4:8]\n",
    "    \n",
    "    # Draw crosses for the positions of the eyes\n",
    "    plt.plot(eye1_x, eye1_y, 'g+', markersize=15)  # Green cross for eye 1\n",
    "    plt.plot(eye2_x, eye2_y, 'g+', markersize=15)  # Green cross for eye 2\n",
    "    \n",
    "    # Determine whether the person is wearing a mask or not\n",
    "    occ_type = row['label'][0][12]\n",
    "    # plt.title('Mask' if occ_type == 1 else f'No Mask - {occ_type}')\n",
    "    plt.title('Simple Occluder' if occ_type == 1 else 'Complex Occluder' if occ_type == 2 else 'Human Body' if occ_type == 3 else 'Unknown Occluder Type')\n",
    "\n",
    "    # Additional information below the image\n",
    "    additional_info = \"\"\"Face Bounding Box (x, y, w, h): {}\\nEye Positions (x1, y1), (x2, y2): ({}, {}), ({}, {})\\nOccluder Bounding Box (x, y, w, h): {}\\nOcc Type: {}\\nOcc Degree: {}\\nGender: {}\\nRace: {}\\nOrientation: {}\\nGlasses Bounding Box (x, y, w, h): {}\\n\"\"\".format(\n",
    "        (x, y, w, h),\n",
    "        eye1_x, eye1_y, eye2_x, eye2_y,\n",
    "        occluder_bbox,\n",
    "        row['label'][0][11],\n",
    "        row['label'][0][13],\n",
    "        row['label'][0][14],\n",
    "        row['label'][0][15],\n",
    "        row['label'][0][16],\n",
    "        row['label'][0][-4:]\n",
    "    )\n",
    "\n",
    "    # plt.text(0, 0, additional_info, fontsize=10, ha='left', va='top')\n",
    "\n",
    "def show_random_faces():\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i in range(5):\n",
    "        random_idx = np.random.randint(len(df))  # Randomly select an index\n",
    "        row = df.iloc[random_idx].copy()  # Get a copy of the row\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        display_image_with_features(row)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def show_selected_faces(rows):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, idx in enumerate(rows, start=1):\n",
    "        row = df.iloc[idx].copy()\n",
    "        plt.subplot(1, 5, i)\n",
    "        display_image_with_features(row)\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "rows = [0, 1, 2, 3, 4]\n",
    "show_selected_faces(rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizes images and adjusts labels accordingly. Uses a size of 224 x 224.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "\n",
    "# Load the .mat file\n",
    "train_data = scipy.io.loadmat(r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\LabelTrainAll.mat')\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(train_data['label_train'][0])\n",
    "\n",
    "# Define the path to the images\n",
    "image_path = r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\train-images'\n",
    "\n",
    "# Function to resize image and update labels\n",
    "def resize_image_and_labels(row, target_size):\n",
    "    # Load the image\n",
    "    img_name = row['imgName'][0]\n",
    "    img = cv2.imread(image_path + '\\\\' + img_name)\n",
    "    \n",
    "    # Resize image\n",
    "    resized_img = cv2.resize(img, target_size)\n",
    "    \n",
    "    # Calculate scaling factors for resizing\n",
    "    fx = target_size[0] / img.shape[1]\n",
    "    fy = target_size[1] / img.shape[0]\n",
    "    \n",
    "    # Update face and occluder coordinates\n",
    "    row['label'][0][:4] = np.round(row['label'][0][:4] * np.array([fx, fy, fx, fy])).astype(int)\n",
    "    row['label'][0][8:12] = np.round(row['label'][0][8:12] * np.array([fx, fy, fx, fy])).astype(int)\n",
    "    row['label'][0][-4:] = np.round(row['label'][0][-4:] * np.array([fx, fy, fx, fy])).astype(int)\n",
    "    \n",
    "    # Update eye coordinates\n",
    "    row['label'][0][4:6] = np.round(row['label'][0][4:6] * np.array([fx, fy])).astype(int)\n",
    "    row['label'][0][6:8] = np.round(row['label'][0][6:8] * np.array([fx, fy])).astype(int)\n",
    "\n",
    "    return resized_img, row\n",
    "\n",
    "# Function to display image with bounding boxes and eye positions\n",
    "def display_image_with_features(img, row):\n",
    "    # Display the image\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # Get the face bounding box\n",
    "    face_bbox = row['label'][0][:4]\n",
    "    x, y, w, h = face_bbox\n",
    "    \n",
    "    # Draw face bounding box\n",
    "    plt.gca().add_patch(patches.Rectangle((x, y), w, h, linewidth=2, edgecolor='r', facecolor='none'))\n",
    "    \n",
    "    # Get the bounding box of the occluder\n",
    "    occluder_bbox = row['label'][0][8:12]\n",
    "    if not np.all(occluder_bbox == -1):\n",
    "        ox, oy, ow, oh = occluder_bbox\n",
    "        # Draw occluder bounding box\n",
    "        plt.gca().add_patch(patches.Rectangle((x + ox, y + oy), ow, oh, linewidth=2, edgecolor='b', facecolor='none'))\n",
    "    \n",
    "    # Get the bounding box of the glasses\n",
    "    glasses_bbox = row['label'][0][-4:]\n",
    "    if not np.all(glasses_bbox == -1):\n",
    "        gx, gy, gw, gh = glasses_bbox\n",
    "        # Draw glasses bounding box\n",
    "        plt.gca().add_patch(patches.Rectangle((x + gx, y + gy), gw, gh, linewidth=2, edgecolor='g', facecolor='none'))\n",
    "    \n",
    "    # Get the positions of the eyes (relative to the face bounding box)\n",
    "    eye1_x, eye1_y, eye2_x, eye2_y = row['label'][0][4:8]\n",
    "    \n",
    "    # Draw crosses for the positions of the eyes\n",
    "    plt.plot(eye1_x, eye1_y, 'g+', markersize=15)  # Green cross for eye 1\n",
    "    plt.plot(eye2_x, eye2_y, 'g+', markersize=15)  # Green cross for eye 2\n",
    "    \n",
    "    # Determine whether the person is wearing a mask or not\n",
    "    occ_type = row['label'][0][12]\n",
    "    plt.title('Simple Occluder' if occ_type == 1 else 'Complex Occluder' if occ_type == 2 else 'Human Body' if occ_type == 3 else 'Unknown Occluder Type')\n",
    "\n",
    "# Display random images with bounding boxes and eye positions\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(5):\n",
    "    random_idx = np.random.randint(len(df))  # Randomly select an index\n",
    "    row = df.iloc[random_idx].copy()  # Get a copy of the row\n",
    "    resized_img, row = resize_image_and_labels(row, (224, 224))\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    display_image_with_features(resized_img, row)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizes images and adjusts labels accordingly v2...uses csv data instead of .mat data.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "\n",
    "# Load the CSV file\n",
    "csv_path = 'csv/MAFA_Training_Data_Unstructured.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "image_path = r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\train-images'\n",
    "\n",
    "# Function to resize image and update labels\n",
    "def resize_image_and_labels(row, target_size, output_dir=None):\n",
    "    # Load the image\n",
    "    img_name = row['imgName']\n",
    "    img = cv2.imread(image_path + '\\\\' + img_name)\n",
    "    \n",
    "    # Resize image\n",
    "    resized_img = cv2.resize(img, target_size)\n",
    "    \n",
    "    # Calculate scaling factors for resizing\n",
    "    fx = target_size[0] / img.shape[1]\n",
    "    fy = target_size[1] / img.shape[0]\n",
    "    \n",
    "    # Update face and occluder coordinates\n",
    "    row['face_x'] = np.round(row['face_x'] * fx).astype(int)\n",
    "    row['face_y'] = np.round(row['face_y'] * fy).astype(int)\n",
    "    row['face_w'] = np.round(row['face_w'] * fx).astype(int)\n",
    "    row['face_h'] = np.round(row['face_h'] * fy).astype(int)\n",
    "    \n",
    "    row['eye1_x'] = np.round(row['eye1_x'] * fx).astype(int)\n",
    "    row['eye1_y'] = np.round(row['eye1_y'] * fy).astype(int)\n",
    "    row['eye2_x'] = np.round(row['eye2_x'] * fx).astype(int)\n",
    "    row['eye2_y'] = np.round(row['eye2_y'] * fy).astype(int)\n",
    "    \n",
    "    row['occluder_x'] = np.round(row['occluder_x'] * fx).astype(int)\n",
    "    row['occluder_y'] = np.round(row['occluder_y'] * fy).astype(int)\n",
    "    row['occluder_w'] = np.round(row['occluder_w'] * fx).astype(int)\n",
    "    row['occluder_h'] = np.round(row['occluder_h'] * fy).astype(int)\n",
    "\n",
    "    return resized_img, row\n",
    "\n",
    "# Function to display image with bounding boxes and eye positions\n",
    "def display_resized_image_with_features(img, row):\n",
    "    # Display the image\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # Draw face bounding box\n",
    "    plt.gca().add_patch(patches.Rectangle((row['face_x'], row['face_y']), row['face_w'], row['face_h'], linewidth=2, edgecolor='r', facecolor='none'))\n",
    "    \n",
    "    # Draw occluder bounding box\n",
    "    plt.gca().add_patch(patches.Rectangle((row['face_x'] + row['occluder_x'], row['face_y'] + row['occluder_y']), row['occluder_w'], row['occluder_h'], linewidth=2, edgecolor='b', facecolor='none'))\n",
    "    \n",
    "    # Draw glasses bounding box\n",
    "    plt.gca().add_patch(patches.Rectangle((row['face_x'] + row['glasses_x'], row['face_y'] + row['glasses_y']), row['glasses_w'], row['glasses_h'], linewidth=2, edgecolor='g', facecolor='none'))\n",
    "    \n",
    "    # Draw crosses for the positions of the eyes\n",
    "    plt.plot(row['eye1_x'], row['eye1_y'], 'g+', markersize=15)  # Green cross for eye 1\n",
    "    plt.plot(row['eye2_x'], row['eye2_y'], 'g+', markersize=15)  # Green cross for eye 2\n",
    "    \n",
    "    # Determine whether the person is wearing a mask or not\n",
    "    occ_type = row['occluder_type']\n",
    "    plt.title('Simple Occluder' if occ_type == 1 else 'Complex Occluder' if occ_type == 2 else 'Human Body' if occ_type == 3 else 'Unknown Occluder Type')\n",
    "\n",
    "# Display random images with bounding boxes and eye positions\n",
    "def resize_random_faces():\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i in range(5):\n",
    "        random_idx = np.random.randint(len(df))  # Randomly select an index\n",
    "        row = df.iloc[random_idx].copy()  # Get a copy of the row\n",
    "        resized_img, row = resize_image_and_labels(row, (224, 224))\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        display_resized_image_with_features(resized_img, row)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def resize_selected_faces(rows):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, idx in enumerate(rows, start=1):\n",
    "        row = df.iloc[idx].copy()\n",
    "        resized_img, row = resize_image_and_labels(row, (224, 224))\n",
    "        plt.subplot(1, 5, i)\n",
    "        display_resized_image_with_features(resized_img, row)\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "# random_idx = np.random.randint(len(df))  # Randomly select an index\n",
    "# rows =- df.iloc[random_idx].copy()\n",
    "rows = [0, 1, 2, 3, 18]\n",
    "resize_random_faces()\n",
    "# resize_selected_faces(rows)\n",
    "# This currently moves the location of the bbxs each times it runs and i'm not entirely sure why. Also the face of 4 is being shifted up for some reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusts the labels of all images accordingly so 224, 224 labels and stores in a csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "\n",
    "# Load the CSV file\n",
    "csv_path = 'csv/MAFA_Training_Data_Unstructured.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "# image_path = r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\train-images'\n",
    "\n",
    "# Function to resize image and update labels\n",
    "def resize_image_and_labels(row, target_size, output_dir=None):\n",
    "    # Load the image\n",
    "    img_name = row['imgName']\n",
    "    img = cv2.imread(image_path + '\\\\' + img_name)\n",
    "    \n",
    "    # Resize image\n",
    "    resized_img = cv2.resize(img, target_size)\n",
    "    \n",
    "    # Calculate scaling factors for resizing\n",
    "    fx = target_size[0] / img.shape[1]\n",
    "    fy = target_size[1] / img.shape[0]\n",
    "    \n",
    "    # Update face and occluder coordinates\n",
    "    row['face_x'] = np.round(row['face_x'] * fx).astype(int)\n",
    "    row['face_y'] = np.round(row['face_y'] * fy).astype(int)\n",
    "    row['face_w'] = np.round(row['face_w'] * fx).astype(int)\n",
    "    row['face_h'] = np.round(row['face_h'] * fy).astype(int)\n",
    "    \n",
    "    row['eye1_x'] = np.round(row['eye1_x'] * fx).astype(int)\n",
    "    row['eye1_y'] = np.round(row['eye1_y'] * fy).astype(int)\n",
    "    row['eye2_x'] = np.round(row['eye2_x'] * fx).astype(int)\n",
    "    row['eye2_y'] = np.round(row['eye2_y'] * fy).astype(int)\n",
    "    \n",
    "    row['occluder_x'] = np.round(row['occluder_x'] * fx).astype(int)\n",
    "    row['occluder_y'] = np.round(row['occluder_y'] * fy).astype(int)\n",
    "    row['occluder_w'] = np.round(row['occluder_w'] * fx).astype(int)\n",
    "    row['occluder_h'] = np.round(row['occluder_h'] * fy).astype(int)\n",
    "\n",
    "    return resized_img, row\n",
    "\n",
    "def resize_all_image_labels():\n",
    "    # Resize all images and update labels\n",
    "    resized_rows = []\n",
    "    for _, row in df.iterrows():\n",
    "        resized_img, resized_row = resize_image_and_labels(row, (224, 224))\n",
    "        resized_rows.append(resized_row)\n",
    "\n",
    "    # Create DataFrame from resized rows\n",
    "    resized_df = pd.DataFrame(resized_rows)\n",
    "\n",
    "    # Save resized DataFrame to CSV\n",
    "    resized_csv_path = 'csv/MAFA_Training_Data_Unstructured_Resized.csv'\n",
    "    resized_df.to_csv(resized_csv_path, index=False)\n",
    "    \n",
    "    print(\"Image Labels have all been resized and saved to csv/MAFA_Training_Data_Unstructured_Resized.csv\")\n",
    "    \n",
    "# resize_all_image_labels()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizes images and adjusts labels accordingly v2...\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "\n",
    "# Load the CSV file\n",
    "csv_path = 'csv/MAFA_Training_Data_Unstructured.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "image_path = r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\train-images'\n",
    "\n",
    "# Function to resize image and update labels\n",
    "def resize_image_and_labels(row, target_size, output_dir=None):\n",
    "    # Load the image\n",
    "    img_name = row['imgName']\n",
    "    img = cv2.imread(image_path + '\\\\' + img_name)\n",
    "    \n",
    "    # Resize image\n",
    "    resized_img = cv2.resize(img, target_size)\n",
    "    \n",
    "    # Calculate scaling factors for resizing\n",
    "    fx = target_size[0] / img.shape[1]\n",
    "    fy = target_size[1] / img.shape[0]\n",
    "    \n",
    "    # Update face and occluder coordinates\n",
    "    row['face_x'] = np.round(row['face_x'] * fx).astype(int)\n",
    "    row['face_y'] = np.round(row['face_y'] * fy).astype(int)\n",
    "    row['face_w'] = np.round(row['face_w'] * fx).astype(int)\n",
    "    row['face_h'] = np.round(row['face_h'] * fy).astype(int)\n",
    "    \n",
    "    row['eye1_x'] = np.round(row['eye1_x'] * fx).astype(int)\n",
    "    row['eye1_y'] = np.round(row['eye1_y'] * fy).astype(int)\n",
    "    row['eye2_x'] = np.round(row['eye2_x'] * fx).astype(int)\n",
    "    row['eye2_y'] = np.round(row['eye2_y'] * fy).astype(int)\n",
    "    \n",
    "    row['occluder_x'] = np.round(row['occluder_x'] * fx).astype(int)\n",
    "    row['occluder_y'] = np.round(row['occluder_y'] * fy).astype(int)\n",
    "    row['occluder_w'] = np.round(row['occluder_w'] * fx).astype(int)\n",
    "    row['occluder_h'] = np.round(row['occluder_h'] * fy).astype(int)\n",
    "\n",
    "    return resized_img, row\n",
    "\n",
    "# Function to display image with bounding boxes and eye positions\n",
    "def display_resized_image_with_features(img, row):\n",
    "    # Display the image\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # Draw face bounding box\n",
    "    plt.gca().add_patch(patches.Rectangle((row['face_x'], row['face_y']), row['face_w'], row['face_h'], linewidth=2, edgecolor='r', facecolor='none'))\n",
    "    \n",
    "    # Draw occluder bounding box\n",
    "    plt.gca().add_patch(patches.Rectangle((row['face_x'] + row['occluder_x'], row['face_y'] + row['occluder_y']), row['occluder_w'], row['occluder_h'], linewidth=2, edgecolor='b', facecolor='none'))\n",
    "    \n",
    "    # Draw glasses bounding box\n",
    "    plt.gca().add_patch(patches.Rectangle((row['face_x'] + row['glasses_x'], row['face_y'] + row['glasses_y']), row['glasses_w'], row['glasses_h'], linewidth=2, edgecolor='g', facecolor='none'))\n",
    "    \n",
    "    # Draw crosses for the positions of the eyes\n",
    "    plt.plot(row['eye1_x'], row['eye1_y'], 'g+', markersize=15)  # Green cross for eye 1\n",
    "    plt.plot(row['eye2_x'], row['eye2_y'], 'g+', markersize=15)  # Green cross for eye 2\n",
    "    \n",
    "    # Determine whether the person is wearing a mask or not\n",
    "    occ_type = row['occluder_type']\n",
    "    plt.title('Simple Occluder' if occ_type == 1 else 'Complex Occluder' if occ_type == 2 else 'Human Body' if occ_type == 3 else 'Unknown Occluder Type')\n",
    "\n",
    "# Display random images with bounding boxes and eye positions\n",
    "def resize_random_faces():\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i in range(5):\n",
    "        random_idx = np.random.randint(len(df))  # Randomly select an index\n",
    "        row = df.iloc[random_idx].copy()  # Get a copy of the row\n",
    "        resized_img, row = resize_image_and_labels(row, (224, 224))\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        display_resized_image_with_features(resized_img, row)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def resize_selected_faces(rows):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, idx in enumerate(rows, start=1):\n",
    "        row = df.iloc[idx].copy()\n",
    "        resized_img, row = resize_image_and_labels(row, (224, 224))\n",
    "        plt.subplot(1, 5, i)\n",
    "        display_resized_image_with_features(resized_img, row)\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puts the data (unstructured) into a csv in order to apply dimensionality reduction on it.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "# Load the .mat file\n",
    "train_data = scipy.io.loadmat(r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\LabelTrainAll.mat')\n",
    "image_dir = r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\train-images'\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(train_data['label_train'][0])\n",
    "\n",
    "# Preprocess DataFrame to remove square brackets\n",
    "df['orgImgName'] = df['orgImgName'].apply(lambda x: x[0])\n",
    "df['imgName'] = df['imgName'].apply(lambda x: x[0])\n",
    "df['label'] = df['label'].apply(lambda x: ', '.join(map(str, x[0])))\n",
    "\n",
    "# Structure the data\n",
    "label_columns = ['face_x', 'face_y', 'face_w', 'face_h', 'eye1_x', 'eye1_y', 'eye2_x', 'eye2_y', \n",
    "                 'occluder_x', 'occluder_y', 'occluder_w', 'occluder_h', 'occ_type', 'occ_degree', \n",
    "                 'gender', 'race', 'orientation', 'glasses_x', 'glasses_y', 'glasses_w', 'glasses_h']\n",
    "df[label_columns] = df['label'].str.split(', ', expand=True)\n",
    "\n",
    "# Convert the bounding box coordinates from strings to floats\n",
    "for col in label_columns:\n",
    "    df[col] = df[col].astype(float)\n",
    "\n",
    "df.drop(columns=['label'], inplace=True)\n",
    "\n",
    "# Define columns for the CSV\n",
    "csv_columns = ['orgImgName', 'imgName', 'face_x', 'face_y', 'face_w', 'face_h', \n",
    "               'eye1_x', 'eye1_y', 'eye2_x', 'eye2_y', 'occluder_x', 'occluder_y', \n",
    "               'gender', 'race', 'orientation', 'glasses_x', 'glasses_y', 'glasses_w', 'glasses_h']\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df[csv_columns].to_csv('csv/MAFA_training_data_unstructured.csv', index=False)\n",
    "\n",
    "print(\"CSV file has been successfully generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correctly structures both training data and the test data into their own csvs\n",
    "\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "\n",
    "# Load the .mat files\n",
    "test_data = scipy.io.loadmat(r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Test\\LabelTestAll.mat')\n",
    "train_data = scipy.io.loadmat(r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\LabelTrainAll.mat')\n",
    "\n",
    "# Convert the test data to a DataFrame\n",
    "test_label_data = test_data['LabelTest'][0]\n",
    "test_rows = []\n",
    "for img_name, label_array in test_label_data:\n",
    "    img_name = img_name[0]\n",
    "    for label in label_array:\n",
    "        row = [img_name] + label.tolist()\n",
    "        test_rows.append(row)\n",
    "\n",
    "# Create a DataFrame for test data\n",
    "test_df = pd.DataFrame(test_rows, columns=['imgName', 'face_x', 'face_y', 'face_w', 'face_h', 'face_type', 'occluder_x', 'occluder_y', 'occluder_w', 'occluder_h', 'occluder_type', 'occluder_degree', 'gender', 'race', 'orientation', 'glasses_x', 'glasses_y', 'glasses_w', 'glasses_h'])\n",
    "\n",
    "# Convert the bounding box coordinates from strings to floats for test data\n",
    "for col in test_df.columns[1:]:\n",
    "    test_df[col] = test_df[col].astype(float)\n",
    "\n",
    "# Save the test DataFrame to a CSV file\n",
    "test_df.to_csv('csv/MAFA_test_data.csv', index=False)\n",
    "print(\"Test CSV file has been successfully generated.\")\n",
    "\n",
    "# Convert the training data to a DataFrame\n",
    "train_label_data = train_data['label_train'][0]\n",
    "train_rows = []\n",
    "for item in train_label_data:\n",
    "    org_img_name = item[0]\n",
    "    img_name = item[1]\n",
    "    label_array = item[2]\n",
    "    for label in label_array:\n",
    "        row = [img_name[0]] + label.tolist()\n",
    "        train_rows.append(row)\n",
    "\n",
    "# Create a DataFrame for training data\n",
    "train_df = pd.DataFrame(train_rows, columns=['imgName', 'face_x', 'face_y', 'face_w', 'face_h', 'eye1_x', 'eye1_y', 'eye2_x', 'eye2_y', 'occluder_x', 'occluder_y', 'occluder_w', 'occluder_h', 'occluder_type', 'occluder_degree', 'gender', 'race', 'orientation', 'glasses_x', 'glasses_y', 'glasses_w', 'glasses_h'])\n",
    "\n",
    "# Convert the bounding box coordinates from strings to floats for training data\n",
    "for col in train_df.columns[1:]:\n",
    "    train_df[col] = train_df[col].astype(float)\n",
    "\n",
    "# Save the training DataFrame to a CSV file\n",
    "train_df.to_csv('csv/MAFA_training_data.csv', index=False)\n",
    "print(\"Training CSV file has been successfully generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correctly structures the test data into a csv\n",
    "\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the .mat file\n",
    "test_data = scipy.io.loadmat(r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Test\\LabelTestAll.mat')\n",
    "image_dir = r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\test-images'\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "label_data = test_data['LabelTest'][0]\n",
    "rows = []\n",
    "for img_name, label_array in label_data:\n",
    "    img_name = img_name[0]  # Get rid of the extra square brackets\n",
    "    for label in label_array:\n",
    "        row = [img_name] + label.tolist()\n",
    "        rows.append(row)\n",
    "\n",
    "# Create a DataFrame from the list of rows\n",
    "df = pd.DataFrame(rows, columns=['imgName', 'face_x', 'face_y', 'face_w', 'face_h', 'face_type', 'occluder_x', 'occluder_y', 'occluder_w', 'occluder_h', 'occluder_type', 'occluder_degree', 'gender', 'race', 'orientation', 'glasses_x', 'glasses_y', 'glasses_w', 'glasses_h'])\n",
    "\n",
    "# Convert the bounding box coordinates from strings to floats\n",
    "for col in df.columns[1:]:\n",
    "    df[col] = df[col].astype(float)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('csv/MAFA_test_data.csv', index=False)\n",
    "print(\"CSV file has been successfully generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing - Dimensionality Analysis, Reduction, and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used - Best Scatterplot representation of the PCA distribution\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data from CSV\n",
    "df = pd.read_csv(\"csv/MAFA_Training_data_PCA.csv\")\n",
    "\n",
    "# Limit the number of unique image names for the legend\n",
    "max_legend_entries = 20\n",
    "unique_img_names = df['orgImgName'].unique()[:max_legend_entries]\n",
    "\n",
    "# sampled_df = df.sample(n=2000)\n",
    "\n",
    "# Create a scatter plot with principal components\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, x='PC1', y='PC2', hue='orgImgName', palette='viridis')\n",
    "plt.title('PCA Visualization of MAFA Training Data')\n",
    "plt.xlabel('Principal Component 1') # Principal Component 1 is the Face BBX\n",
    "plt.ylabel('Principal Component 2') # Principal Component 1 is the Occluder BBX\n",
    "plt.legend(title='Image Name', labels=unique_img_names, loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unused - Best Scatterplot representation of the PCA distribution - Just the Scatterplot\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data from CSV\n",
    "df = pd.read_csv(\"csv/MAFA_Training_data_PCA.csv\")\n",
    "\n",
    "# Limit the number of unique image names for the legend\n",
    "max_legend_entries = 20\n",
    "unique_img_names = df['orgImgName'].unique()[:max_legend_entries]\n",
    "\n",
    "# sampled_df = df.sample(n=2000)\n",
    "\n",
    "# Create a scatter plot with principal components\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, x='PC1', y='PC2', hue='orgImgName', palette='viridis')\n",
    "plt.title('PCA Visualization of MAFA Training Data')\n",
    "plt.xlabel('Principal Component 1') # Principal Component 1 is the Face BBX\n",
    "plt.ylabel('Principal Component 2') # Principal Component 1 is the Occluder BBX\n",
    "plt.legend(title='Image Name', labels=unique_img_names, loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used - Plotting of the PCA results and using K-means mappings...\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load the transformed data from the CSV file\n",
    "df = pd.read_csv('csv/MAFA_Training_data_PCA.csv')\n",
    "\n",
    "# Limit the number of unique image names for the legend\n",
    "max_legend_entries = 20\n",
    "unique_img_names = df['orgImgName'].unique()[:max_legend_entries]\n",
    "\n",
    "# sampled_df = df.sample(n=2000) # Can be used to select a random sample of size n\n",
    "\n",
    "# Create a scatter plot with principal components\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, x='PC1', y='PC2', hue='orgImgName', palette='viridis')\n",
    "plt.title('PCA Visualization of MAFA Training Data')\n",
    "plt.xlabel('Principal Component 1') # Principal Component 1 is the Face BBX\n",
    "plt.ylabel('Principal Component 2') # Principal Component 1 is the Occluder BBX\n",
    "plt.legend(title='Image Name', labels=unique_img_names, loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Assuming df_pca contains the data with PC1 and PC2 columns\n",
    "# Perform K-means clustering\n",
    "kmeans = KMeans(n_clusters=3)  # Specify the number of clusters\n",
    "clusters = kmeans.fit_predict(df[['PC1', 'PC2']])\n",
    "\n",
    "# Visualize clusters\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(df['PC1'], df['PC2'], c=clusters, cmap='viridis')\n",
    "plt.title('K-means Clustering of PCA Data')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizes images and adjusts labels accordingly. Uses a size of 224 x 224.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "\n",
    "# Function to resize image and update labels\n",
    "def resize_image_and_labels(row, target_size):\n",
    "    # Load the image\n",
    "    img_name = row['imgName'][0]\n",
    "    img = cv2.imread(image_path + '\\\\' + img_name)\n",
    "    \n",
    "    # Resize image\n",
    "    resized_img = cv2.resize(img, target_size)\n",
    "    \n",
    "    # Calculate scaling factors for resizing\n",
    "    fx = target_size[0] / img.shape[1]\n",
    "    fy = target_size[1] / img.shape[0]\n",
    "    \n",
    "    # Update face and occluder coordinates\n",
    "    row['label'][0][:4] = np.round(row['label'][0][:4] * np.array([fx, fy, fx, fy])).astype(int)\n",
    "    row['label'][0][8:12] = np.round(row['label'][0][8:12] * np.array([fx, fy, fx, fy])).astype(int)\n",
    "    row['label'][0][-4:] = np.round(row['label'][0][-4:] * np.array([fx, fy, fx, fy])).astype(int)\n",
    "    \n",
    "    # Update eye coordinates\n",
    "    row['label'][0][4:6] = np.round(row['label'][0][4:6] * np.array([fx, fy])).astype(int)\n",
    "    row['label'][0][6:8] = np.round(row['label'][0][6:8] * np.array([fx, fy])).astype(int)\n",
    "\n",
    "    return resized_img, row\n",
    "\n",
    "# Function to display image with bounding boxes and eye positions\n",
    "def display_image_with_features(img, row):\n",
    "    # Display the image\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # Get the face bounding box\n",
    "    face_bbox = row['label'][0][:4]\n",
    "    x, y, w, h = face_bbox\n",
    "    \n",
    "    # Draw face bounding box\n",
    "    plt.gca().add_patch(patches.Rectangle((x, y), w, h, linewidth=2, edgecolor='r', facecolor='none'))\n",
    "    \n",
    "    # Get the bounding box of the occluder\n",
    "    occluder_bbox = row['label'][0][8:12]\n",
    "    if not np.all(occluder_bbox == -1):\n",
    "        ox, oy, ow, oh = occluder_bbox\n",
    "        # Draw occluder bounding box\n",
    "        plt.gca().add_patch(patches.Rectangle((x + ox, y + oy), ow, oh, linewidth=2, edgecolor='b', facecolor='none'))\n",
    "    \n",
    "    # Get the bounding box of the glasses\n",
    "    glasses_bbox = row['label'][0][-4:]\n",
    "    if not np.all(glasses_bbox == -1):\n",
    "        gx, gy, gw, gh = glasses_bbox\n",
    "        # Draw glasses bounding box\n",
    "        plt.gca().add_patch(patches.Rectangle((x + gx, y + gy), gw, gh, linewidth=2, edgecolor='g', facecolor='none'))\n",
    "    \n",
    "    # Get the positions of the eyes (relative to the face bounding box)\n",
    "    eye1_x, eye1_y, eye2_x, eye2_y = row['label'][0][4:8]\n",
    "    \n",
    "    # Draw crosses for the positions of the eyes\n",
    "    plt.plot(eye1_x, eye1_y, 'g+', markersize=15)  # Green cross for eye 1\n",
    "    plt.plot(eye2_x, eye2_y, 'g+', markersize=15)  # Green cross for eye 2\n",
    "    \n",
    "    # Determine whether the person is wearing a mask or not\n",
    "    occ_type = row['label'][0][12]\n",
    "    plt.title('Simple Occluder' if occ_type == 1 else 'Complex Occluder' if occ_type == 2 else 'Human Body' if occ_type == 3 else 'Unknown Occluder Type')\n",
    "\n",
    "# Display random images with bounding boxes and eye positions\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(5):\n",
    "    random_idx = np.random.randint(len(df))  # Randomly select an index\n",
    "    row = df.iloc[random_idx].copy()  # Get a copy of the row\n",
    "    resized_img, row = resize_image_and_labels(row, (224, 224))\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    display_image_with_features(resized_img, row)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing - Structuring of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Structuring and Preprocessing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "# Load the .mat file\n",
    "train_data = scipy.io.loadmat(r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\LabelTrainAll.mat')\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(train_data['label_train'][0])\n",
    "\n",
    "# Preprocess DataFrame to remove square brackets\n",
    "df['orgImgName'] = df['orgImgName'].apply(lambda x: x[0])\n",
    "df['imgName'] = df['imgName'].apply(lambda x: x[0])\n",
    "df['label'] = df['label'].apply(lambda x: ', '.join(map(str, x[0])))\n",
    "\n",
    "### Missing Value validation\n",
    "\n",
    "# Identify missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Fill in the missing values with the mean value.\n",
    "# df.fillna(df.mean(), inplace=True) # Cannot be done with images, thus we just remove the row completely.\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "### Validating the values column to ensure correct number of elements\n",
    "\n",
    "# Validate the number of elements in the 'label' column\n",
    "valid_label_count = df['label'].apply(lambda x: len(x.split(', ')) == 21)\n",
    "missing_values = valid_label_count.value_counts()[True]  # Count missing values\n",
    "print(\"\\nNumber of elements with expected label array size:\", missing_values)\n",
    "# print(\"Missing values:\", missing_values)\n",
    "\n",
    "### Double checking for duplicate values\n",
    "\n",
    "# Check for duplicate rows and removes them if they exist\n",
    "duplicates = df[df.duplicated()]\n",
    "print(f\"Duplicates duplicated: ${duplicates}\")\n",
    "df.drop_duplicates(inplace=True) # Removes the duplicates\n",
    "\n",
    "### Removing outliers\n",
    "\n",
    "# Identify outliers using Z-score...The Z-score measures how many deviations within the mean a data point is. \n",
    "# This doesn't work with MaskedFace recognition because all of the data is unique to that particular image. There is no way of guessing the location of the face.\n",
    "# z_scores = (df['column_name'] - df['column_name'].mean()) / df['column_name'].std()\n",
    "# outliers = df[(z_scores > 3) | (z_scores < -3)]\n",
    "\n",
    "# df = df[(z_scores < 3) & (z_scores > -3)]\n",
    "\n",
    "# Save the DataFrame to a CSV file without square brackets\n",
    "df.to_csv('csv/MAFA_Label_Train.csv', index=False)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(\"\\nCleaned DataFrame:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Structuring and Preprocessing v2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "# Load the .mat file\n",
    "train_data = scipy.io.loadmat(r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\LabelTrainAll.mat')\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(train_data['label_train'][0])\n",
    "\n",
    "# Preprocess DataFrame to remove square brackets\n",
    "df['orgImgName'] = df['orgImgName'].apply(lambda x: x[0])\n",
    "df['imgName'] = df['imgName'].apply(lambda x: x[0])\n",
    "df['label'] = df['label'].apply(lambda x: ', '.join(map(str, x[0])))\n",
    "\n",
    "### Missing Value validation\n",
    "\n",
    "# Identify missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Fill in the missing values with the mean value.\n",
    "# df.fillna(df.mean(), inplace=True) # Cannot be done with images, thus we just remove the row completely.\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "### Validating the values column to ensure correct number of elements\n",
    "\n",
    "# Validate the number of elements in the 'label' column\n",
    "valid_label_count = df['label'].apply(lambda x: len(x.split(', ')) == 21)\n",
    "missing_values = valid_label_count.value_counts()[True]  # Count missing values\n",
    "print(\"\\nNumber of elements with expected label array size:\", missing_values)\n",
    "# print(\"Missing values:\", missing_values)\n",
    "\n",
    "### Double checking for duplicate values\n",
    "\n",
    "# Check for duplicate rows and removes them if they exist\n",
    "duplicates = df[df.duplicated()]\n",
    "print(f\"Duplicates duplicated: ${duplicates}\")\n",
    "df.drop_duplicates(inplace=True) # Removes the duplicates\n",
    "\n",
    "### Structure the data and convert into a csv\n",
    "\n",
    "# Extract bounding box information\n",
    "label_columns = ['face_x', 'face_y', 'face_w', 'face_h', 'eye1_x', 'eye1_y', 'eye2_x', 'eye2_y', 'occluder_x', 'occluder_y', 'occluder_w', 'occluder_h', 'occ_type', 'occ_degree', 'gender', 'race', 'orientation', 'glasses_x', 'glasses_y', 'glasses_w', 'glasses_h']\n",
    "df[label_columns] = df['label'].str.split(', ', expand=True)\n",
    "\n",
    "# Create separate columns for bounding boxes\n",
    "df['face_bbx'] = df[['face_x', 'face_y', 'face_w', 'face_h']].values.tolist()\n",
    "df['left_eye_bbx'] = df[['eye1_x', 'eye1_y']].values.tolist()\n",
    "df['right_eye_bbx'] = df[['eye2_x', 'eye2_y']].values.tolist()\n",
    "df['occluder_bbx'] = df[['occluder_x', 'occluder_y', 'occluder_w', 'occluder_h']].values.tolist()\n",
    "df['occluder_type'] = df['occ_type']\n",
    "df['occluder_degree'] = df['occ_degree']\n",
    "df['face_gender'] = df['gender']\n",
    "df['face_race'] = df['race']\n",
    "df['face_orientation'] = df['orientation']\n",
    "df['glasses_bbx'] = df[['glasses_x', 'glasses_y', 'glasses_w', 'glasses_h']].values.tolist()\n",
    "\n",
    "# Drop the original columns\n",
    "df.drop(columns=label_columns, inplace=True)\n",
    "\n",
    "# Convert the extracted columns to numeric type\n",
    "df[['face_bbx', 'left_eye_bbx', 'right_eye_bbx', 'occluder_bbx', 'occluder_type', 'occluder_degree', 'face_gender', 'face_race', 'face_orientation', 'glasses_bbx']] = df[['face_bbx', 'left_eye_bbx', 'right_eye_bbx', 'occluder_bbx', 'occluder_type', 'occluder_degree', 'face_gender', 'face_race', 'face_orientation', 'glasses_bbx']].map(np.array)\n",
    "\n",
    "# Drop the original 'label' column\n",
    "df.drop(columns=['label'], inplace=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file without square brackets\n",
    "df.to_csv('csv/MAFA_Label_Train.csv', index=False)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(\"\\nCleaned and structured DataFrame:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Structuring and Preprocessing v3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "import os\n",
    "\n",
    "# Load the .mat file\n",
    "train_data = scipy.io.loadmat(r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\LabelTrainAll.mat')\n",
    "image_dir = r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\train-images'\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(train_data['label_train'][0])\n",
    "\n",
    "# Preprocess DataFrame to remove square brackets\n",
    "df['orgImgName'] = df['orgImgName'].apply(lambda x: x[0])\n",
    "df['imgName'] = df['imgName'].apply(lambda x: x[0])\n",
    "df['label'] = df['label'].apply(lambda x: ', '.join(map(str, x[0])))\n",
    "\n",
    "### Missing Value validation\n",
    "\n",
    "# Identify missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Fill in the missing values with the mean value.\n",
    "# df.fillna(df.mean(), inplace=True) # Cannot be done with images, thus we just remove the row completely.\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "### Validating the values column to ensure correct number of elements\n",
    "\n",
    "# Validate the number of elements in the 'label' column\n",
    "valid_label_count = df['label'].apply(lambda x: len(x.split(', ')) == 21)\n",
    "missing_values = valid_label_count.value_counts()[True]  # Count missing values\n",
    "print(\"\\nNumber of elements with expected label array size:\", missing_values)\n",
    "# print(\"Missing values:\", missing_values)\n",
    "\n",
    "### Double checking for duplicate values - Does nothing with them, just a note at the moment.\n",
    "\n",
    "def find_duplicates_images(image_dir):\n",
    "    \"\"\"\n",
    "    Find duplicate images in a directory based on their perceptual hashes and print them.\n",
    "    \"\"\"\n",
    "    # Dictionary to store hashes and corresponding filenames\n",
    "    hash_dict = {}\n",
    "    \n",
    "    # List to store duplicate image filenames\n",
    "    duplicate_images = []\n",
    "    \n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(image_dir):\n",
    "        # Check if the file is an image\n",
    "        if filename.endswith((\".jpg\", \".png\")):\n",
    "            # Get the full file path\n",
    "            filepath = os.path.join(image_dir, filename)\n",
    "            \n",
    "            # Open the image and calculate its hash\n",
    "            with Image.open(filepath) as img:\n",
    "                hash_val = str(imagehash.average_hash(img))\n",
    "            \n",
    "            # Check if the hash already exists in the dictionary\n",
    "            if hash_val in hash_dict:\n",
    "                # Add the current filename and the filename already stored in hash_dict\n",
    "                duplicate_images.append((filename, hash_dict[hash_val]))\n",
    "            else:\n",
    "                # Add the hash and filename to the dictionary\n",
    "                hash_dict[hash_val] = filename\n",
    "                \n",
    "    # Print the duplicate images\n",
    "    if duplicate_images:\n",
    "        print(\"Duplicate images found:\")\n",
    "        for img1, img2 in duplicate_images:\n",
    "            print(f\"{img2} is a duplicate of {img1}\")\n",
    "    else:\n",
    "        print(\"No duplicate images found.\")\n",
    "\n",
    "# Call the function to find and print duplicate images\n",
    "find_duplicates_images(image_dir)\n",
    "\n",
    "### Structure the data and convert into a csv\n",
    "\n",
    "# Extract bounding box information\n",
    "label_columns = ['face_x', 'face_y', 'face_w', 'face_h', 'eye1_x', 'eye1_y', 'eye2_x', 'eye2_y', 'occluder_x', 'occluder_y', 'occluder_w', 'occluder_h', 'occ_type', 'occ_degree', 'gender', 'race', 'orientation', 'glasses_x', 'glasses_y', 'glasses_w', 'glasses_h']\n",
    "df[label_columns] = df['label'].str.split(', ', expand=True)\n",
    "\n",
    "# Create separate columns for bounding boxes\n",
    "df['face_bbx'] = df[['face_x', 'face_y', 'face_w', 'face_h']].values.tolist()\n",
    "df['left_eye_bbx'] = df[['eye1_x', 'eye1_y']].values.tolist()\n",
    "df['right_eye_bbx'] = df[['eye2_x', 'eye2_y']].values.tolist()\n",
    "df['occluder_bbx'] = df[['occluder_x', 'occluder_y', 'occluder_w', 'occluder_h']].values.tolist()\n",
    "df['occluder_type'] = df['occ_type']\n",
    "df['occluder_degree'] = df['occ_degree']\n",
    "df['face_gender'] = df['gender']\n",
    "df['face_race'] = df['race']\n",
    "df['face_orientation'] = df['orientation']\n",
    "df['glasses_bbx'] = df[['glasses_x', 'glasses_y', 'glasses_w', 'glasses_h']].values.tolist()\n",
    "\n",
    "# Drop the original columns\n",
    "df.drop(columns=label_columns, inplace=True)\n",
    "\n",
    "# Convert the extracted columns to numeric type\n",
    "df[['face_bbx', 'left_eye_bbx', 'right_eye_bbx', 'occluder_bbx', 'occluder_type', 'occluder_degree', 'face_gender', 'face_race', 'face_orientation', 'glasses_bbx']] = df[['face_bbx', 'left_eye_bbx', 'right_eye_bbx', 'occluder_bbx', 'occluder_type', 'occluder_degree', 'face_gender', 'face_race', 'face_orientation', 'glasses_bbx']].map(np.array)\n",
    "\n",
    "# Drop the original 'label' column\n",
    "df.drop(columns=['label'], inplace=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file without square brackets\n",
    "df.to_csv('csv/MAFA_Label_Train.csv', index=False)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(\"\\nCleaned and structured DataFrame:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Structuring and Preprocessing v4\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "import os\n",
    "import logging\n",
    "\n",
    "if not os.path.exists('logs'):\n",
    "    os.makedirs('logs')\n",
    "\n",
    "# Load the .mat file\n",
    "train_data = scipy.io.loadmat(r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\LabelTrainAll.mat')\n",
    "image_dir = r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\train-images'\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(train_data['label_train'][0])\n",
    "\n",
    "# Preprocess DataFrame to remove square brackets\n",
    "df['orgImgName'] = df['orgImgName'].apply(lambda x: x[0])\n",
    "df['imgName'] = df['imgName'].apply(lambda x: x[0])\n",
    "df['label'] = df['label'].apply(lambda x: ', '.join(map(str, x[0])))\n",
    "\n",
    "### Missing Value validation\n",
    "\n",
    "# Identify missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Fill in the missing values with the mean value.\n",
    "# df.fillna(df.mean(), inplace=True) # Cannot be done with images, thus we just remove the row completely.\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "### Validating the values column to ensure correct number of elements\n",
    "\n",
    "# Validate the number of elements in the 'label' column\n",
    "valid_label_count = df['label'].apply(lambda x: len(x.split(', ')) == 21)\n",
    "missing_values = valid_label_count.value_counts()[True]  # Count missing values\n",
    "print(\"\\nNumber of elements with expected label array size:\", missing_values)\n",
    "# print(\"Missing values:\", missing_values)\n",
    "\n",
    "### Double checking for duplicate values - Does nothing with them, just a note at the moment.\n",
    "\n",
    "logging.basicConfig(filename='logs\\duplicate_images.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def find_duplicate_images_2(image_dir):\n",
    "    \"\"\"\n",
    "    Find duplicate images in a directory based on their perceptual hashes and log them.\n",
    "    \"\"\"\n",
    "    # Dictionary to store hashes and corresponding filenames\n",
    "    hash_dict = {}\n",
    "    \n",
    "    # List to store duplicate image filenames\n",
    "    duplicate_images = []\n",
    "    \n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(image_dir):\n",
    "        # Check if the file is an image\n",
    "        if filename.endswith((\".jpg\", \".png\")):\n",
    "            # Get the full file path\n",
    "            filepath = os.path.join(image_dir, filename)\n",
    "            \n",
    "            # Open the image and calculate its hash\n",
    "            try:\n",
    "                with Image.open(filepath) as img:\n",
    "                    hash_val = str(imagehash.average_hash(img))\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing image {filename}: {e}\")\n",
    "                continue\n",
    "            \n",
    "            # Check if the hash already exists in the dictionary\n",
    "            if hash_val in hash_dict:\n",
    "                # Add the current filename and the filename already stored in hash_dict\n",
    "                duplicate_images.append((filename, hash_dict[hash_val]))\n",
    "                logging.info(f\"Duplicate image found: {filename} is a duplicate of {hash_dict[hash_val]}\")\n",
    "            else:\n",
    "                # Add the hash and filename to the dictionary\n",
    "                hash_dict[hash_val] = filename\n",
    "                \n",
    "    # Log the results\n",
    "    if duplicate_images:\n",
    "        logging.info(f\"Total {len(duplicate_images)} duplicate images found.\")\n",
    "    else:\n",
    "        logging.info(\"No duplicate images found.\")\n",
    "\n",
    "# Call the function to find and print duplicate images\n",
    "find_duplicate_images_2(image_dir)\n",
    "\n",
    "### Structure the data and convert into a csv\n",
    "\n",
    "# Extract bounding box information\n",
    "label_columns = ['face_x', 'face_y', 'face_w', 'face_h', 'eye1_x', 'eye1_y', 'eye2_x', 'eye2_y', 'occluder_x', 'occluder_y', 'occluder_w', 'occluder_h', 'occ_type', 'occ_degree', 'gender', 'race', 'orientation', 'glasses_x', 'glasses_y', 'glasses_w', 'glasses_h']\n",
    "df[label_columns] = df['label'].str.split(', ', expand=True)\n",
    "\n",
    "# Create separate columns for bounding boxes\n",
    "df['face_bbx'] = df[['face_x', 'face_y', 'face_w', 'face_h']].values.tolist()\n",
    "df['left_eye_bbx'] = df[['eye1_x', 'eye1_y']].values.tolist()\n",
    "df['right_eye_bbx'] = df[['eye2_x', 'eye2_y']].values.tolist()\n",
    "df['occluder_bbx'] = df[['occluder_x', 'occluder_y', 'occluder_w', 'occluder_h']].values.tolist()\n",
    "df['occluder_type'] = df['occ_type']\n",
    "df['occluder_degree'] = df['occ_degree']\n",
    "df['face_gender'] = df['gender']\n",
    "df['face_race'] = df['race']\n",
    "df['face_orientation'] = df['orientation']\n",
    "df['glasses_bbx'] = df[['glasses_x', 'glasses_y', 'glasses_w', 'glasses_h']].values.tolist()\n",
    "\n",
    "# Drop the original columns\n",
    "df.drop(columns=label_columns, inplace=True)\n",
    "\n",
    "# Convert the extracted columns to numeric type\n",
    "df[['face_bbx', 'left_eye_bbx', 'right_eye_bbx', 'occluder_bbx', 'occluder_type', 'occluder_degree', 'face_gender', 'face_race', 'face_orientation', 'glasses_bbx']] = df[['face_bbx', 'left_eye_bbx', 'right_eye_bbx', 'occluder_bbx', 'occluder_type', 'occluder_degree', 'face_gender', 'face_race', 'face_orientation', 'glasses_bbx']].map(np.array)\n",
    "\n",
    "# Drop the original 'label' column\n",
    "df.drop(columns=['label'], inplace=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file without square brackets\n",
    "df.to_csv('csv/MAFA_Label_Train.csv', index=False)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(\"\\nCleaned and structured DataFrame:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Structuring and Preprocessing v5\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "import os\n",
    "import logging\n",
    "\n",
    "if not os.path.exists('logs'):\n",
    "    os.makedirs('logs')\n",
    "\n",
    "# Load the .mat file\n",
    "train_data = scipy.io.loadmat(r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\LabelTrainAll.mat')\n",
    "image_dir = r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\train-images'\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(train_data['label_train'][0])\n",
    "\n",
    "# Preprocess DataFrame to remove square brackets\n",
    "df['orgImgName'] = df['orgImgName'].apply(lambda x: x[0])\n",
    "df['imgName'] = df['imgName'].apply(lambda x: x[0])\n",
    "df['label'] = df['label'].apply(lambda x: ', '.join(map(str, x[0])))\n",
    "\n",
    "### Missing Value validation\n",
    "\n",
    "# Identify missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Fill in the missing values with the mean value.\n",
    "# df.fillna(df.mean(), inplace=True) # Cannot be done with images, thus we just remove the row completely.\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "### Validating the values column to ensure correct number of elements\n",
    "\n",
    "# Validate the number of elements in the 'label' column\n",
    "valid_label_count = df['label'].apply(lambda x: len(x.split(', ')) == 21)\n",
    "missing_values = valid_label_count.value_counts()[True]  # Count missing values\n",
    "print(\"\\nNumber of elements with expected label array size:\", missing_values)\n",
    "# print(\"Missing values:\", missing_values)\n",
    "\n",
    "### Double checking for duplicate values - Does nothing with them, just a note at the moment.\n",
    "\n",
    "logging.basicConfig(filename='logs\\duplicate_images.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def find_duplicate_images(image_dir):\n",
    "    \"\"\"\n",
    "    Find duplicate images in a directory based on their perceptual hashes and log them.\n",
    "    \"\"\"\n",
    "    # Dictionary to store hashes and corresponding filenames\n",
    "    hash_dict = {}\n",
    "    \n",
    "    # List to store duplicate image filenames\n",
    "    duplicate_images = []\n",
    "    \n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(image_dir):\n",
    "        # Check if the file is an image\n",
    "        if filename.endswith((\".jpg\", \".png\")):\n",
    "            # Get the full file path\n",
    "            filepath = os.path.join(image_dir, filename)\n",
    "            \n",
    "            # Open the image and calculate its hash\n",
    "            try:\n",
    "                with Image.open(filepath) as img:\n",
    "                    hash_val = str(imagehash.average_hash(img))\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing image {filename}: {e}\")\n",
    "                continue\n",
    "            \n",
    "            # Check if the hash already exists in the dictionary\n",
    "            if hash_val in hash_dict:\n",
    "                # Add the current filename and the filename already stored in hash_dict\n",
    "                duplicate_images.append((filename, hash_dict[hash_val]))\n",
    "                logging.info(f\"Duplicate image found: {filename} is a duplicate of {hash_dict[hash_val]}\")\n",
    "            else:\n",
    "                # Add the hash and filename to the dictionary\n",
    "                hash_dict[hash_val] = filename\n",
    "                \n",
    "    # Log the results\n",
    "    if duplicate_images:\n",
    "        logging.info(f\"Total {len(duplicate_images)} duplicate images found.\")\n",
    "    else:\n",
    "        logging.info(\"No duplicate images found.\")\n",
    "\n",
    "# Call the function to find and print duplicate images\n",
    "find_duplicate_images(image_dir)\n",
    "\n",
    "### Structure the data and convert into a csv\n",
    "\n",
    "# Extract bounding box information\n",
    "label_columns = ['face_x', 'face_y', 'face_w', 'face_h', 'eye1_x', 'eye1_y', 'eye2_x', 'eye2_y', 'occluder_x', 'occluder_y', 'occluder_w', 'occluder_h', 'occ_type', 'occ_degree', 'gender', 'race', 'orientation', 'glasses_x', 'glasses_y', 'glasses_w', 'glasses_h']\n",
    "df[label_columns] = df['label'].str.split(', ', expand=True)\n",
    "\n",
    "# Create separate columns for bounding boxes\n",
    "df['face_bbx'] = df.apply(lambda row: ', '.join(row[['face_x', 'face_y', 'face_w', 'face_h']].astype(str)), axis=1)\n",
    "df['left_eye_bbx'] = df.apply(lambda row: ', '.join(row[['eye1_x', 'eye1_y']].astype(str)), axis=1)\n",
    "df['right_eye_bbx'] = df.apply(lambda row: ', '.join(row[['eye2_x', 'eye2_y']].astype(str)), axis=1)\n",
    "df['occluder_bbx'] = df.apply(lambda row: ', '.join(row[['occluder_x', 'occluder_y', 'occluder_w', 'occluder_h']].astype(str)), axis=1)\n",
    "df['occluder_type'] = df['occ_type']\n",
    "df['occluder_degree'] = df['occ_degree']\n",
    "# df['face_gender'] = df['gender'] # Removing these columns is a form of dimensionality reduction\n",
    "# df['face_race'] = df['race']\n",
    "# df['face_orientation'] = df['orientation']\n",
    "# df['glasses_bbx'] = df.apply(lambda row: ', '.join(row[['glasses_x', 'glasses_y', 'glasses_w', 'glasses_h']].astype(str)), axis=1)\n",
    "\n",
    "# Drop the original columns\n",
    "df.drop(columns=label_columns, inplace=True)\n",
    "\n",
    "# Convert the extracted columns to numeric type\n",
    "df[['face_bbx', 'left_eye_bbx', 'right_eye_bbx', 'occluder_bbx', 'occluder_type', 'occluder_degree', 'face_gender', 'face_race', 'face_orientation', 'glasses_bbx']] = df[['face_bbx', 'left_eye_bbx', 'right_eye_bbx', 'occluder_bbx', 'occluder_type', 'occluder_degree', 'face_gender', 'face_race', 'face_orientation', 'glasses_bbx']].map(np.array)\n",
    "\n",
    "# Drop the original 'label' column\n",
    "df.drop(columns=['label'], inplace=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file without square brackets\n",
    "df.to_csv('csv/MAFA_Label_Train.csv', index=False)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(\"\\nCleaned and structured DataFrame:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used - Data Structuring and Preprocessing v6\n",
    "\n",
    "if not os.path.exists('logs'):\n",
    "    os.makedirs('logs')\n",
    "\n",
    "# Load the .mat file\n",
    "train_data = scipy.io.loadmat(r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\LabelTrainAll.mat')\n",
    "image_dir = r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\train-images'\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(train_data['label_train'][0])\n",
    "\n",
    "# Preprocess DataFrame to remove square brackets\n",
    "df['orgImgName'] = df['orgImgName'].apply(lambda x: x[0])\n",
    "df['imgName'] = df['imgName'].apply(lambda x: x[0])\n",
    "df['label'] = df['label'].apply(lambda x: ', '.join(map(str, x[0])))\n",
    "\n",
    "### Missing Value validation\n",
    "\n",
    "# Identify missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Fill in the missing values with the mean value.\n",
    "# df.fillna(df.mean(), inplace=True) # Cannot be done with images, thus we just remove the row completely.\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "### Validating the values column to ensure correct number of elements\n",
    "\n",
    "# Validate the number of elements in the 'label' column\n",
    "valid_label_count = df['label'].apply(lambda x: len(x.split(', ')) == 21)\n",
    "missing_values = valid_label_count.value_counts()[True]  # Count missing values\n",
    "print(\"\\nNumber of elements with expected label array size:\", missing_values)\n",
    "# print(\"Missing values:\", missing_values)\n",
    "\n",
    "### Double checking for duplicate values - Does nothing with them, just a note at the moment.\n",
    "\n",
    "logging.basicConfig(filename='logs\\duplicate_images.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def find_duplicate_images(image_dir):\n",
    "    \"\"\"\n",
    "    Find duplicate images in a directory based on their perceptual hashes and log them.\n",
    "    \"\"\"\n",
    "    # Dictionary to store hashes and corresponding filenames\n",
    "    hash_dict = {}\n",
    "    \n",
    "    # List to store duplicate image filenames\n",
    "    duplicate_images = []\n",
    "    \n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(image_dir):\n",
    "        # Check if the file is an image\n",
    "        if filename.endswith((\".jpg\", \".png\")):\n",
    "            # Get the full file path\n",
    "            filepath = os.path.join(image_dir, filename)\n",
    "            \n",
    "            # Open the image and calculate its hash\n",
    "            try:\n",
    "                with Image.open(filepath) as img:\n",
    "                    hash_val = str(imagehash.average_hash(img))\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing image {filename}: {e}\")\n",
    "                continue\n",
    "            \n",
    "            # Check if the hash already exists in the dictionary\n",
    "            if hash_val in hash_dict:\n",
    "                # Add the current filename and the filename already stored in hash_dict\n",
    "                duplicate_images.append((filename, hash_dict[hash_val]))\n",
    "                logging.info(f\"Duplicate image found: {filename} is a duplicate of {hash_dict[hash_val]}\")\n",
    "            else:\n",
    "                # Add the hash and filename to the dictionary\n",
    "                hash_dict[hash_val] = filename\n",
    "                \n",
    "    # Log the results\n",
    "    if duplicate_images:\n",
    "        logging.info(f\"Total {len(duplicate_images)} duplicate images found.\")\n",
    "    else:\n",
    "        logging.info(\"No duplicate images found.\")\n",
    "\n",
    "# Call the function to find and print duplicate images\n",
    "# find_duplicate_images(image_dir)\n",
    "\n",
    "### Structure the data and convert into a csv\n",
    "\n",
    "# Extract bounding box information\n",
    "label_columns = ['face_x', 'face_y', 'face_w', 'face_h', 'eye1_x', 'eye1_y', 'eye2_x', 'eye2_y', 'occluder_x', 'occluder_y', 'occluder_w', 'occluder_h', 'occ_type', 'occ_degree', 'gender', 'race', 'orientation', 'glasses_x', 'glasses_y', 'glasses_w', 'glasses_h']\n",
    "df[label_columns] = df['label'].str.split(', ', expand=True)\n",
    "\n",
    "# Convert the bounding box coordinates from strings to floats\n",
    "for col in label_columns:\n",
    "    df[col] = df[col].astype(float)\n",
    "\n",
    "# Group bounding box coordinates under their respective columns\n",
    "df['face_bbx'] = df.apply(lambda row: ', '.join(map(str, row[['face_x', 'face_y', 'face_w', 'face_h']])), axis=1)\n",
    "df['left_eye_pos'] = df.apply(lambda row: ', '.join(map(str, row[['eye1_x', 'eye1_y']])), axis=1)\n",
    "df['right_eye_pos'] = df.apply(lambda row: ', '.join(map(str, row[['eye2_x', 'eye2_y']])), axis=1)\n",
    "df['occluder_bbx'] = df.apply(lambda row: ', '.join(map(str, row[['occluder_x', 'occluder_y', 'occluder_w', 'occluder_h']])), axis=1)\n",
    "df['occluder_type'] = df['occ_type']\n",
    "df['occluder_degree'] = df['occ_degree']\n",
    "df['face_gender'] = df['gender'] # Removing these columns is a form of dimensionality reduction\n",
    "df['face_race'] = df['race']\n",
    "df['face_orientation'] = df['orientation']\n",
    "df['glasses_bbx'] = df.apply(lambda row: ', '.join(map(str, row[['glasses_x', 'glasses_y', 'glasses_w', 'glasses_h']])), axis=1)\n",
    "\n",
    "# Drop the original columns\n",
    "df.drop(columns=label_columns, inplace=True)\n",
    "\n",
    "# Drop the original 'label' column\n",
    "df.drop(columns=['label'], inplace=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('csv/MAFA_Training_Data_Structured.csv', index=False)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(\"\\nCleaned and structured DataFrame:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing - Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Augmentation - Rotation, Blue, Flipped, and brightness adjustment. No bbx.\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def augment_and_plot(row):\n",
    "    # Load the image\n",
    "    img_name = row['imgName']\n",
    "    img = cv2.imread(image_path + '\\\\' + img_name)\n",
    "    \n",
    "    # Convert image to RGB for displaying with matplotlib\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Plot the original image\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.subplot(1, 5, 1)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.title('Original')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Augmentation 1: Rotation\n",
    "    rotation_angle = 30\n",
    "    rotation_matrix = cv2.getRotationMatrix2D((img.shape[1] / 2, img.shape[0] / 2), rotation_angle, 1)\n",
    "    rotated_img = cv2.warpAffine(img, rotation_matrix, (img.shape[1], img.shape[0]))\n",
    "    plt.subplot(1, 5, 2)\n",
    "    plt.imshow(cv2.cvtColor(rotated_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Rotated')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Augmentation 2: Blur\n",
    "    blurred_img = cv2.GaussianBlur(img, (15, 15), 0)\n",
    "    plt.subplot(1, 5, 3)\n",
    "    plt.imshow(cv2.cvtColor(blurred_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Blurred')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Augmentation 3: Flipping\n",
    "    flipped_img = cv2.flip(img, 1)  # 1 for horizontal flip\n",
    "    plt.subplot(1, 5, 4)\n",
    "    plt.imshow(cv2.cvtColor(flipped_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Flipped')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Augmentation 4: Brightness adjustment\n",
    "    brightness_adjusted_img = cv2.convertScaleAbs(img, alpha=2.0, beta=50)\n",
    "    plt.subplot(1, 5, 5)\n",
    "    plt.imshow(cv2.cvtColor(brightness_adjusted_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Brightness Adjusted')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Testing the function\n",
    "# Assume `df` is your DataFrame containing image data\n",
    "row_index = 0  # Choose a specific row for testing\n",
    "row = df.iloc[row_index]\n",
    "augment_and_plot(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds bbx to the one above. Rotated bbx doesn't work - misplaced.\n",
    "\n",
    "def augment_and_plot(row):\n",
    "    # Load the image\n",
    "    img_name = row['imgName']\n",
    "    img = cv2.imread(image_path + '\\\\' + img_name)\n",
    "    \n",
    "    # Convert image to RGB for displaying with matplotlib\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Plot the original image with bounding box\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.subplot(1, 5, 1)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.title('Original')\n",
    "    plt.axis('off')\n",
    "    draw_bounding_box(row, img.shape[1], img.shape[0])\n",
    "    \n",
    "    # Augmentation 1: Rotation\n",
    "    rotation_angle = 30\n",
    "    rotation_matrix = cv2.getRotationMatrix2D((img.shape[1] / 2, img.shape[0] / 2), rotation_angle, 1)\n",
    "    rotated_img = cv2.warpAffine(img, rotation_matrix, (img.shape[1], img.shape[0]))\n",
    "    plt.subplot(1, 5, 2)\n",
    "    plt.imshow(cv2.cvtColor(rotated_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Rotated')\n",
    "    plt.axis('off')\n",
    "    draw_bounding_box(row, img.shape[1], img.shape[0], rotation_angle)\n",
    "    \n",
    "    # Augmentation 2: Blur\n",
    "    blurred_img = cv2.GaussianBlur(img, (15, 15), 0)\n",
    "    plt.subplot(1, 5, 3)\n",
    "    plt.imshow(cv2.cvtColor(blurred_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Blurred')\n",
    "    plt.axis('off')\n",
    "    draw_bounding_box(row, img.shape[1], img.shape[0])\n",
    "    \n",
    "    # Augmentation 3: Flipping\n",
    "    flipped_img = cv2.flip(img, 1)  # 1 for horizontal flip\n",
    "    plt.subplot(1, 5, 4)\n",
    "    plt.imshow(cv2.cvtColor(flipped_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Flipped')\n",
    "    plt.axis('off')\n",
    "    draw_bounding_box(row, img.shape[1], img.shape[0], flip=True)\n",
    "    \n",
    "    # Augmentation 4: Brightness adjustment\n",
    "    brightness_adjusted_img = cv2.convertScaleAbs(img, alpha=2.0, beta=50)\n",
    "    plt.subplot(1, 5, 5)\n",
    "    plt.imshow(cv2.cvtColor(brightness_adjusted_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Brightness Adjusted')\n",
    "    plt.axis('off')\n",
    "    draw_bounding_box(row, img.shape[1], img.shape[0])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to draw bounding boxes\n",
    "def draw_bounding_box(row, img_width, img_height, rotation_angle=0, flip=False):\n",
    "    face_x, face_y, face_w, face_h = row['face_x'], row['face_y'], row['face_w'], row['face_h']\n",
    "    occluder_x, occluder_y, occluder_w, occluder_h = row['occluder_x'], row['occluder_y'], row['occluder_w'], row['occluder_h']\n",
    "    glasses_x, glasses_y, glasses_w, glasses_h = row['glasses_x'], row['glasses_y'], row['glasses_w'], row['glasses_h']\n",
    "    \n",
    "    # Adjust occluder coordinates relative to the face bounding box\n",
    "    occluder_x += face_x\n",
    "    occluder_y += face_y\n",
    "    \n",
    "    if rotation_angle != 0:\n",
    "        # Rotate bounding boxes\n",
    "        face_x, face_y = rotate_point(face_x, face_y, img_width / 2, img_height / 2, rotation_angle)\n",
    "        occluder_x, occluder_y = rotate_point(occluder_x, occluder_y, img_width / 2, img_height / 2, rotation_angle)\n",
    "        glasses_x, glasses_y = rotate_point(glasses_x, glasses_y, img_width / 2, img_height / 2, rotation_angle)\n",
    "    \n",
    "    if flip:\n",
    "        # Flip bounding boxes\n",
    "        face_x = img_width - face_x - face_w\n",
    "        occluder_x = img_width - occluder_x - occluder_w\n",
    "        glasses_x = img_width - glasses_x - glasses_w\n",
    "    \n",
    "    plt.gca().add_patch(patches.Rectangle((face_x, face_y), face_w, face_h, linewidth=2, edgecolor='r', facecolor='none'))\n",
    "    plt.gca().add_patch(patches.Rectangle((occluder_x, occluder_y), occluder_w, occluder_h, linewidth=2, edgecolor='b', facecolor='none'))\n",
    "    plt.gca().add_patch(patches.Rectangle((glasses_x, glasses_y), glasses_w, glasses_h, linewidth=2, edgecolor='g', facecolor='none'))\n",
    "\n",
    "\n",
    "# Function to rotate a point around an origin\n",
    "def rotate_point(x, y, cx, cy, angle):\n",
    "    angle_rad = np.deg2rad(angle)\n",
    "    x_new = (x - cx) * np.cos(angle_rad) - (y - cy) * np.sin(angle_rad) + cx\n",
    "    y_new = (x - cx) * np.sin(angle_rad) + (y - cy) * np.cos(angle_rad) + cy\n",
    "    return x_new, y_new\n",
    "\n",
    "# Testing the function\n",
    "# Assume `df` is your DataFrame containing image data\n",
    "row_index = 0  # Choose a specific row for testing\n",
    "row = df.iloc[row_index]\n",
    "augment_and_plot(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS THE CODE TO BLUR AND CAN BE USED FOR AUGMENTATION - Both skimage and cv2 have been used.\n",
    "\n",
    "import cv2\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, filters\n",
    "\n",
    "# Load bounding box annotations from the .mat file\n",
    "mat_file = r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\WIDERFACE\\wider_face_split\\wider_face_split\\wider_face_train.mat'\n",
    "annotations = sio.loadmat(mat_file)\n",
    "\n",
    "# Read images from the 'WIDER_train' directory\n",
    "image_dir = 'C:\\\\Users\\\\alexw\\\\OneDrive\\\\Documents\\\\03_Education\\\\University\\\\University_Programming\\\\Python\\Big_Data\\\\Coursework\\Datasets\\WIDERFACE\\WIDER_train\\WIDER_train\\\\images\\\\0--Parade\\\\0_Parade_marchingband_1_849.jpg'\n",
    "image_filenames = annotations['file_list']\n",
    "\n",
    "# Load the image using skimage\n",
    "img = io.imread(image_dir)\n",
    "\n",
    "# Apply blur using skimage (adjust the sigma parameter for the desired blur strength)\n",
    "blurred_img_skimage = filters.gaussian(img, sigma=9)\n",
    "\n",
    "# Apply blur using OpenCV (adjust the (5, 5) kernel size for the desired blur strength)\n",
    "blurred_img_cv2 = cv2.blur(img, (15, 15))  # You can adjust (15, 15) to another size\n",
    "\n",
    "# Display the original and blurred images using matplotlib\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "axes[0].imshow(img)\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(blurred_img_skimage)\n",
    "axes[1].set_title('Blurred (skimage)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(blurred_img_cv2)\n",
    "axes[2].set_title('Blurred (OpenCV)')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS THE CODE TO ROTATE AND CAN BE USED FOR AUGMENTATION - Both skimage and cv2 have been used.\n",
    "\n",
    "import cv2\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, filters, transform\n",
    "import numpy as np\n",
    "\n",
    "# Load bounding box annotations from the .mat file\n",
    "mat_file = r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\WIDERFACE\\wider_face_split\\wider_face_split\\wider_face_train.mat'\n",
    "annotations = sio.loadmat(mat_file)\n",
    "\n",
    "# Read images from the 'WIDER_train' directory\n",
    "image_dir = 'C:\\\\Users\\\\alexw\\\\OneDrive\\\\Documents\\\\03_Education\\\\University\\\\University_Programming\\\\Python\\Big_Data\\\\Coursework\\Datasets\\WIDERFACE\\WIDER_train\\WIDER_train\\\\images\\\\0--Parade\\\\0_Parade_marchingband_1_849.jpg'\n",
    "image_filenames = annotations['file_list']\n",
    "\n",
    "# Load the image using skimage\n",
    "img = io.imread(image_dir)\n",
    "\n",
    "# Generate a random rotation angle between -30 and 30 degrees\n",
    "# rotation_angle = 30\n",
    "rotation_angle = np.random.uniform(-360, 360)\n",
    "\n",
    "rotated_img_skimage = transform.rotate(img, rotation_angle, resize=False)\n",
    "\n",
    "# Rotate the image using OpenCV\n",
    "rows, cols, _ = img.shape\n",
    "rotation_matrix = cv2.getRotationMatrix2D((cols / 2, rows / 2), rotation_angle, 1)\n",
    "rotated_img_cv2 = cv2.warpAffine(img, rotation_matrix, (cols, rows))\n",
    "\n",
    "# Display the original and rotated images using matplotlib\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "axes[0].imshow(img)\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(rotated_img_skimage)\n",
    "axes[1].set_title(f'{rotation_angle:.2f} degrees (Skimage)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(rotated_img_cv2)\n",
    "axes[2].set_title(f'{rotation_angle:.2f} degrees (OpenCV)')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for finding duplicate images within the training image set using image hashing. \n",
    "\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "import os\n",
    "\n",
    "def find_duplicates_images(image_dir):\n",
    "    \"\"\"\n",
    "    Find duplicate images in a directory based on their perceptual hashes and print them.\n",
    "    \"\"\"\n",
    "    # Dictionary to store hashes and corresponding filenames\n",
    "    hash_dict = {}\n",
    "    \n",
    "    # List to store duplicate image filenames\n",
    "    duplicate_images = []\n",
    "    \n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(image_dir):\n",
    "        # Check if the file is an image\n",
    "        if filename.endswith((\".jpg\", \".png\")):\n",
    "            # Get the full file path\n",
    "            filepath = os.path.join(image_dir, filename)\n",
    "            \n",
    "            # Open the image and calculate its hash\n",
    "            with Image.open(filepath) as img:\n",
    "                hash_val = str(imagehash.average_hash(img))\n",
    "            \n",
    "            # Check if the hash already exists in the dictionary\n",
    "            if hash_val in hash_dict:\n",
    "                # Add the current filename and the filename already stored in hash_dict\n",
    "                duplicate_images.append((filename, hash_dict[hash_val]))\n",
    "            else:\n",
    "                # Add the hash and filename to the dictionary\n",
    "                hash_dict[hash_val] = filename\n",
    "                \n",
    "    # Print the duplicate images\n",
    "    if duplicate_images:\n",
    "        print(\"Duplicate images found:\")\n",
    "        for img1, img2 in duplicate_images:\n",
    "            print(f\"{img2} is a duplicate of {img1}\")\n",
    "    else:\n",
    "        print(\"No duplicate images found.\")\n",
    "\n",
    "# Directory containing images\n",
    "image_dir = r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\train-images\\images'\n",
    "\n",
    "# Call the function to find and print duplicate images\n",
    "find_duplicates_images(image_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used for image hashing. Ensuring that there are no duplicate images in the dataset. DELETES THE IMAGE IN THE FOLDER SO WATCH OUT.\n",
    "\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "import os\n",
    "\n",
    "# Function to find duplicate images in a directory\n",
    "def find_duplicate_images(image_dir):\n",
    "    # Dictionary to store hashes and corresponding filenames\n",
    "    hash_dict = {}\n",
    "    \n",
    "    # List to store duplicate image filenames\n",
    "    duplicate_images = []\n",
    "    \n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(image_dir):\n",
    "        # Check if the file is an image\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            # Get the full file path\n",
    "            filepath = os.path.join(image_dir, filename)\n",
    "            \n",
    "            # Open the image and calculate its hash\n",
    "            with Image.open(filepath) as img:\n",
    "                hash_val = str(imagehash.average_hash(img))\n",
    "            \n",
    "            # Check if the hash already exists in the dictionary\n",
    "            if hash_val in hash_dict:\n",
    "                # Add the filename to the list of duplicates\n",
    "                duplicate_images.append(filename)\n",
    "            else:\n",
    "                # Add the hash and filename to the dictionary\n",
    "                hash_dict[hash_val] = filename\n",
    "                \n",
    "    # Iterate through the list of duplicate images\n",
    "    for duplicate in duplicate_images:\n",
    "        # Get the full file path of the duplicate image\n",
    "        duplicate_path = os.path.join(image_dir, duplicate)\n",
    "        \n",
    "        # Delete the duplicate image\n",
    "        os.remove(duplicate_path)\n",
    "        \n",
    "        print(f\"Deleted duplicate image: {duplicate}\")\n",
    "\n",
    "# Directory containing the images\n",
    "image_dir = r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\images'\n",
    "# find_duplicate_images(image_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Successfully trains model, and then predicts the test images and displays the results with the image\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the CSV file\n",
    "image_labels = pd.read_csv(r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Masked_Face\\csv\\MAFA_Training_Data_Unstructured.csv')\n",
    "path_to_images = r\"C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\train-images\"\n",
    "\n",
    "# Add mask_label column - defines whether the occluder in the image is a simple mask, complex mask or whether it is a human bodypart occluding.\n",
    "image_labels['mask_label'] = np.where((image_labels['occluder_type'] == 1) | (image_labels['occluder_type'] == 2), 1, 0)\n",
    "\n",
    "# Define image size\n",
    "img_size = 100\n",
    "\n",
    "# Load and preprocess images\n",
    "def preprocess_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (img_size, img_size))\n",
    "    img = img / 255.0 # Normalize pixel values\n",
    "    return img\n",
    "\n",
    "# Load images and labels\n",
    "X = np.array([preprocess_image(os.path.join(path_to_images, img_name)) for img_name in image_labels['imgName']])\n",
    "y = to_categorical(image_labels['mask_label'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define image augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20, # Rotate images by 20 degrees\n",
    "    width_shift_range=0.1, # Shift images horizontally by 10%\n",
    "    height_shift_range=0.1, # Shift images vertically by 10%\n",
    "    shear_range=0.2, # Shear angle in counter-clockwise direction\n",
    "    zoom_range=0.2, # Zoom range from 80% to 120%\n",
    "    horizontal_flip=True, # Randomly flip images horizontally\n",
    "    fill_mode='nearest' # Fill mode for filling in newly created pixels\n",
    ")\n",
    "\n",
    "# Create augmented data generator\n",
    "augmented_datagen = datagen.flow(X_train, y_train, batch_size=32)\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax') # 2 output nodes for binary classification (with mask or without mask)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit_generator(augmented_datagen, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "precision = precision_score(y_test_classes, y_pred_classes)\n",
    "recall = recall_score(y_test_classes, y_pred_classes)\n",
    "f1 = f1_score(y_test_classes, y_pred_classes)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv(r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Masked_Face\\csv\\MAFA_test_data.csv')\n",
    "test_images_path = r\"C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Test\\test-images\"\n",
    "\n",
    "# Display test images with face mask caption\n",
    "for _, row in test_data.iterrows():\n",
    "    img_name = row['imgName']\n",
    "    img_path = os.path.join(test_images_path, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    face_x, face_y, face_w, face_h = row[['face_x', 'face_y', 'face_w', 'face_h']]\n",
    "    occluder_type = row['occluder_type']\n",
    "\n",
    "    # Check if the occluder type is a mask\n",
    "    is_mask = occluder_type == 1 or occluder_type == 2\n",
    "\n",
    "    # Draw a bounding box around the face\n",
    "    cv2.rectangle(img, (int(face_x), int(face_y)), (int(face_x + face_w), int(face_y + face_h)), (0, 255, 0), 2)\n",
    "\n",
    "    # Add a caption indicating if the person is wearing a mask or not\n",
    "    caption = \"Wearing a face mask\" if is_mask else \"Not wearing a face mask\"\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.title(caption)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORKING CNN - Accuracy of 0.9223 with image resizing but no augmentation.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Load the CSV file\n",
    "image_labels = pd.read_csv(r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Masked_Face\\csv\\MAFA_Training_Data_Unstructured.csv')\n",
    "path_to_images = r\"C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\train-images\"\n",
    "\n",
    "# Add mask_label column\n",
    "image_labels['mask_label'] = np.where((image_labels['occluder_type'] == 1) | (image_labels['occluder_type'] == 2), 1, 0)\n",
    "\n",
    "# Define image size\n",
    "IMG_SIZE = 100 # 224 x 224 ideal image size but too large to create an array.\n",
    "\n",
    "# Load and preprocess images\n",
    "def preprocess_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    img = img / 255.0  # Normalize pixel values\n",
    "    return img\n",
    "\n",
    "# Load images and labels\n",
    "X = np.array([preprocess_image(os.path.join(path_to_images, img_name)) for img_name in image_labels['imgName']])\n",
    "y = to_categorical(image_labels['mask_label'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')  # 2 output nodes for binary classification (with mask or without mask)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "precision = precision_score(y_test_classes, y_pred_classes)\n",
    "recall = recall_score(y_test_classes, y_pred_classes)\n",
    "f1 = f1_score(y_test_classes, y_pred_classes)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORKING CNN - Accuracy of 0.9223 with image augmentation - Accuracy seems to have converged upon 0.922 thus further processing or augmentation will not improve.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load the CSV file\n",
    "image_labels = pd.read_csv(r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Masked_Face\\csv\\MAFA_Training_Data_Unstructured.csv')\n",
    "path_to_images = r\"C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\train-images\"\n",
    "\n",
    "# Add mask_label column - defines whether the occluder in the image is a simple mask, complex mask or whether it is a human bodypart occluding.\n",
    "image_labels['mask_label'] = np.where((image_labels['occluder_type'] == 1) | (image_labels['occluder_type'] == 2), 1, 0)\n",
    "\n",
    "# Define image size\n",
    "img_size = 100\n",
    "\n",
    "# Load and preprocess images\n",
    "def preprocess_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (img_size, img_size))\n",
    "    img = img / 255.0  # Normalize pixel values\n",
    "    return img\n",
    "\n",
    "# Load images and labels\n",
    "X = np.array([preprocess_image(os.path.join(path_to_images, img_name)) for img_name in image_labels['imgName']])\n",
    "y = to_categorical(image_labels['mask_label'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define image augmentation parameters - Doesn't really do anything and the model tends to converge around 0.9220\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,      # Rotate images by 20 degrees\n",
    "    width_shift_range=0.1,  # Shift images horizontally by 10%\n",
    "    height_shift_range=0.1, # Shift images vertically by 10%\n",
    "    shear_range=0.2,        # Shear angle in counter-clockwise direction\n",
    "    zoom_range=0.2,         # Zoom range from 80% to 120%\n",
    "    horizontal_flip=True,   # Randomly flip images horizontally\n",
    "    fill_mode='nearest'     # Fill mode for filling in newly created pixels\n",
    ")\n",
    "\n",
    "# Create augmented data generator\n",
    "augmented_datagen = datagen.flow(X_train, y_train, batch_size=32)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')  # 2 output nodes for binary classification (with mask or without mask)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(augmented_datagen, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "precision = precision_score(y_test_classes, y_pred_classes)\n",
    "recall = recall_score(y_test_classes, y_pred_classes)\n",
    "f1 = f1_score(y_test_classes, y_pred_classes)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working SVM Model...Accuracy 0.8765 on 10% of the data.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the CSV file\n",
    "image_labels = pd.read_csv(r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Masked_Face\\csv\\MAFA_Training_Data_Unstructured.csv')\n",
    "\n",
    "path_to_images = r\"C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\train-images\"\n",
    "\n",
    "# Add mask_label column\n",
    "image_labels['mask_label'] = np.where((image_labels['occluder_type'] == 1) | (image_labels['occluder_type'] == 2), 1, 0)\n",
    "\n",
    "# Define image size\n",
    "img_size = 100\n",
    "\n",
    "# Load and preprocess images\n",
    "def preprocess_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (img_size, img_size))\n",
    "    img = img.flatten() / 255.0  # Flatten and normalize pixel values\n",
    "    return img\n",
    "\n",
    "# Load images and labels\n",
    "X = np.array([preprocess_image(os.path.join(path_to_images, img_name)) for img_name in image_labels['imgName']])\n",
    "y = image_labels['mask_label'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reduce training data size (e.g. 10% of the data)\n",
    "reduce_factor = 0.1\n",
    "num_samples_to_train = int(len(X_train) * reduce_factor)\n",
    "X_train_reduced = X_train[:num_samples_to_train]\n",
    "y_train_reduced = y_train[:num_samples_to_train]\n",
    "\n",
    "# Create and train the SVM model\n",
    "svm_model = SVC(kernel='linear', probability=True)\n",
    "svm_model.fit(X_train_reduced, y_train_reduced)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "y_pred = svm_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5343894899536321\n",
      "Predictions: [1. 1. 2. ... 2. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Working SVM Model...Accuracy 0.534 on unstructured raw data. Confusion matrix doesn't work.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "\n",
    "def confusionM(y_true, y_predict, target_names):\n",
    "    # Function for visualization\n",
    "    cMatrix = confusion_matrix(y_true, y_predict)\n",
    "    df_cm = pd.DataFrame(cMatrix, index=target_names, columns=target_names)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv(r\"C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Masked_Face\\csv\\MAFA_Training_Data_Unstructured.csv\")\n",
    "\n",
    "# Assuming 'occluder_type' represents whether someone is wearing a face mask or not (1 = wearing, 2 = not wearing)\n",
    "# Create features X and target y\n",
    "X = data[['face_x', 'face_y', 'face_w', 'face_h', 'eye1_x', 'eye1_y', 'eye2_x', 'eye2_y', 'occluder_x', 'occluder_y', 'occluder_w', 'occluder_h']]\n",
    "y = data['occluder_type']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_true = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize SVM classifier\n",
    "svc = svm.SVC(kernel='linear')\n",
    "\n",
    "# Train the SVM model\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Test the SVM model\n",
    "accuracy = svc.score(X_test_scaled, y_true)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Predict on test data\n",
    "y_predict = svc.predict(X_test_scaled)\n",
    "print(\"Predictions:\", y_predict)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "# confusionM(y_true, y_predict, ['Not Wearing', 'Wearing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working SVM Model...Accuracy 0.527, very basic model...Might be a good one to showcase.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def confusionM(y_true, y_predict, target_names):\n",
    "    # Function for visualization\n",
    "    cMatrix = confusion_matrix(y_true, y_predict)\n",
    "    df_cm = pd.DataFrame(cMatrix, index=target_names, columns=target_names)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv(r\"C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Masked_Face\\csv\\MAFA_Training_Data_Unstructured.csv\")\n",
    "\n",
    "# Assuming 'occluder_type' represents whether someone is wearing a face mask or not (1 = wearing, 2 = not wearing)\n",
    "# Create features X and target y\n",
    "X = data[['face_x', 'face_y', 'face_w', 'face_h', 'eye1_x', 'eye1_y', 'eye2_x', 'eye2_y', 'occluder_x', 'occluder_y', 'occluder_w', 'occluder_h']]\n",
    "y = data['occluder_type']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize SVM classifier\n",
    "svc = SVC(kernel='rbf', C=10, gamma='auto', class_weight='balanced')\n",
    "\n",
    "# Train the SVM model\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_predict = svc.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = svc.score(X_test_scaled, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "# confusionM(y_test, y_predict, ['Wearing', 'Not Wearing'])  # Adjust the target names accordingly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.535935085007728\n"
     ]
    }
   ],
   "source": [
    "# Working SVM Model...Accuracy 0.536. Improving... Used the resized dataset.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def confusionM(y_true, y_predict, target_names):\n",
    "    # Function for visualization\n",
    "    cMatrix = confusion_matrix(y_true, y_predict)\n",
    "    df_cm = pd.DataFrame(cMatrix, index=target_names, columns=target_names)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv(r\"C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Masked_Face\\csv\\MAFA_Training_Data_Unstructured_Resized.csv\")\n",
    "\n",
    "# Assuming 'occluder_type' represents whether someone is wearing a face mask or not (1 = wearing, 2 = not wearing)\n",
    "# Create features X and target y\n",
    "X = data[['face_x', 'face_y', 'face_w', 'face_h', 'eye1_x', 'eye1_y', 'eye2_x', 'eye2_y', 'occluder_x', 'occluder_y', 'occluder_w', 'occluder_h']]\n",
    "y = data['occluder_type']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize SVM classifier\n",
    "svc = SVC(kernel='rbf', C=10, gamma='auto', class_weight='balanced')\n",
    "\n",
    "# Train the SVM model\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_predict = svc.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = svc.score(X_test_scaled, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "# confusionM(y_test, y_predict, ['Wearing', 'Not Wearing'])  # Adjust the target names accordingly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Might Come in Useful but not wanted right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizes images and adjusts labels accordingly v2...Demonstrates image resizing.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "\n",
    "# Load the CSV file\n",
    "csv_path = 'csv/MAFA_Training_Data_Unstructured.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "image_path = r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\train-images'\n",
    "\n",
    "# Function to resize image and update labels\n",
    "def resize_image_and_labels(row, target_size, output_dir=None):\n",
    "    # Load the image\n",
    "    img_name = row['imgName']\n",
    "    img = cv2.imread(image_path + '\\\\' + img_name)\n",
    "    \n",
    "    # Resize image\n",
    "    resized_img = cv2.resize(img, target_size)\n",
    "    \n",
    "    # Calculate scaling factors for resizing\n",
    "    fx = target_size[0] / img.shape[1]\n",
    "    fy = target_size[1] / img.shape[0]\n",
    "    \n",
    "    # Update face and occluder coordinates\n",
    "    row['face_x'] = np.round(row['face_x'] * fx).astype(int)\n",
    "    row['face_y'] = np.round(row['face_y'] * fy).astype(int)\n",
    "    row['face_w'] = np.round(row['face_w'] * fx).astype(int)\n",
    "    row['face_h'] = np.round(row['face_h'] * fy).astype(int)\n",
    "    \n",
    "    row['eye1_x'] = np.round(row['eye1_x'] * fx).astype(int)\n",
    "    row['eye1_y'] = np.round(row['eye1_y'] * fy).astype(int)\n",
    "    row['eye2_x'] = np.round(row['eye2_x'] * fx).astype(int)\n",
    "    row['eye2_y'] = np.round(row['eye2_y'] * fy).astype(int)\n",
    "    \n",
    "    row['occluder_x'] = np.round(row['occluder_x'] * fx).astype(int)\n",
    "    row['occluder_y'] = np.round(row['occluder_y'] * fy).astype(int)\n",
    "    row['occluder_w'] = np.round(row['occluder_w'] * fx).astype(int)\n",
    "    row['occluder_h'] = np.round(row['occluder_h'] * fy).astype(int)\n",
    "\n",
    "    return resized_img, row\n",
    "\n",
    "# Function to display image with bounding boxes and eye positions\n",
    "def display_resized_image_with_features(img, row):\n",
    "    # Display the image\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # Draw face bounding box\n",
    "    plt.gca().add_patch(patches.Rectangle((row['face_x'], row['face_y']), row['face_w'], row['face_h'], linewidth=2, edgecolor='r', facecolor='none'))\n",
    "    \n",
    "    # Draw occluder bounding box\n",
    "    plt.gca().add_patch(patches.Rectangle((row['face_x'] + row['occluder_x'], row['face_y'] + row['occluder_y']), row['occluder_w'], row['occluder_h'], linewidth=2, edgecolor='b', facecolor='none'))\n",
    "    \n",
    "    # Draw glasses bounding box\n",
    "    plt.gca().add_patch(patches.Rectangle((row['face_x'] + row['glasses_x'], row['face_y'] + row['glasses_y']), row['glasses_w'], row['glasses_h'], linewidth=2, edgecolor='g', facecolor='none'))\n",
    "    \n",
    "    # Draw crosses for the positions of the eyes\n",
    "    plt.plot(row['eye1_x'], row['eye1_y'], 'g+', markersize=15)  # Green cross for eye 1\n",
    "    plt.plot(row['eye2_x'], row['eye2_y'], 'g+', markersize=15)  # Green cross for eye 2\n",
    "    \n",
    "    # Determine whether the person is wearing a mask or not\n",
    "    occ_type = row['occluder_type']\n",
    "    plt.title('Simple Occluder' if occ_type == 1 else 'Complex Occluder' if occ_type == 2 else 'Human Body' if occ_type == 3 else 'Unknown Occluder Type')\n",
    "\n",
    "# Display random images with bounding boxes and eye positions\n",
    "def resize_random_faces():\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i in range(5):\n",
    "        random_idx = np.random.randint(len(df))  # Randomly select an index\n",
    "        row = df.iloc[random_idx].copy()  # Get a copy of the row\n",
    "        resized_img, row = resize_image_and_labels(row, (224, 224))\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        display_resized_image_with_features(resized_img, row)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def resize_selected_faces(rows):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, idx in enumerate(rows, start=1):\n",
    "        row = df.iloc[idx].copy()\n",
    "        resized_img, row = resize_image_and_labels(row, (224, 224))\n",
    "        plt.subplot(1, 5, i)\n",
    "        display_resized_image_with_features(resized_img, row)\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "# random_idx = np.random.randint(len(df))  # Randomly select an index\n",
    "# rows =- df.iloc[random_idx].copy()\n",
    "rows = [0, 1, 2, 3, 4]\n",
    "resize_selected_faces(rows)\n",
    "# resize_selected_faces(rows)\n",
    "# This currently moves the location of the bbxs each times it runs and i'm not entirely sure why. Also the face of 4 is being shifted up for some reason.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the structure of the csv for both training and testing data, where multiple faces were stored as multiple arrays within an array. THIS WORKS BUT NOT SOMETHING I THINK I WANT...\n",
    "# But i think the issue is that we can't pull the data out as easily as when we store them each on seperate rows...It becomes more convoluted.\n",
    "\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "\n",
    "# Load the .mat files\n",
    "test_data = scipy.io.loadmat(r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Test\\LabelTestAll.mat')\n",
    "train_data = scipy.io.loadmat(r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\LabelTrainAll.mat')\n",
    "\n",
    "# Convert the test data to a DataFrame\n",
    "test_label_data = test_data['LabelTest'][0]\n",
    "test_rows = []\n",
    "for img_name, label_array in test_label_data:\n",
    "    img_name = img_name[0]\n",
    "    face_data = label_array.tolist()  # Convert label array to list\n",
    "    test_rows.append([img_name, face_data])\n",
    "\n",
    "# Create a DataFrame for test data\n",
    "test_df = pd.DataFrame(test_rows, columns=['imgName', 'faces'])\n",
    "\n",
    "# Save the test DataFrame to a CSV file\n",
    "test_df.to_csv('csv/MAFA_test_data.csv', index=False)\n",
    "print(\"Test CSV file has been successfully generated.\")\n",
    "\n",
    "# Convert the training data to a DataFrame\n",
    "train_label_data = train_data['label_train'][0]\n",
    "train_rows = []\n",
    "for item in train_label_data:\n",
    "    org_img_name = item[0]\n",
    "    img_name = item[1]\n",
    "    label_array = item[2]\n",
    "    face_data = label_array.tolist()  # Convert label array to list\n",
    "    train_rows.append([img_name[0], face_data])\n",
    "\n",
    "# Create a DataFrame for training data\n",
    "train_df = pd.DataFrame(train_rows, columns=['imgName', 'faces'])\n",
    "\n",
    "# Save the training DataFrame to a CSV file\n",
    "train_df.to_csv('csv/MAFA_training_data.csv', index=False)\n",
    "print(\"Training CSV file has been successfully generated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds bbx to the one above. Rotated bbx doesn't work - misplaced.\n",
    "\n",
    "def augment_and_plot(row):\n",
    "    # Load the image\n",
    "    img_name = row['imgName']\n",
    "    img = cv2.imread(image_path + '\\\\' + img_name)\n",
    "    \n",
    "    # Convert image to RGB for displaying with matplotlib\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Plot the original image with bounding box\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.subplot(1, 5, 1)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.title('Original')\n",
    "    plt.axis('off')\n",
    "    draw_bounding_box(row, img.shape[1], img.shape[0])\n",
    "    \n",
    "    # Augmentation 1: Rotation\n",
    "    rotation_angle = 30\n",
    "    rotation_matrix = cv2.getRotationMatrix2D((img.shape[1] / 2, img.shape[0] / 2), rotation_angle, 1)\n",
    "    rotated_img = cv2.warpAffine(img, rotation_matrix, (img.shape[1], img.shape[0]))\n",
    "    plt.subplot(1, 5, 2)\n",
    "    plt.imshow(cv2.cvtColor(rotated_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Rotated')\n",
    "    plt.axis('off')\n",
    "    draw_bounding_box(row, img.shape[1], img.shape[0], rotation_angle)\n",
    "    \n",
    "    # Augmentation 2: Blur\n",
    "    blurred_img = cv2.GaussianBlur(img, (15, 15), 0)\n",
    "    plt.subplot(1, 5, 3)\n",
    "    plt.imshow(cv2.cvtColor(blurred_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Blurred')\n",
    "    plt.axis('off')\n",
    "    draw_bounding_box(row, img.shape[1], img.shape[0])\n",
    "    \n",
    "    # Augmentation 3: Flipping\n",
    "    flipped_img = cv2.flip(img, 1)  # 1 for horizontal flip\n",
    "    plt.subplot(1, 5, 4)\n",
    "    plt.imshow(cv2.cvtColor(flipped_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Flipped')\n",
    "    plt.axis('off')\n",
    "    draw_bounding_box(row, img.shape[1], img.shape[0], flip=True)\n",
    "    \n",
    "    # Augmentation 4: Brightness adjustment\n",
    "    brightness_adjusted_img = cv2.convertScaleAbs(img, alpha=2.0, beta=50)\n",
    "    plt.subplot(1, 5, 5)\n",
    "    plt.imshow(cv2.cvtColor(brightness_adjusted_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Brightness Adjusted')\n",
    "    plt.axis('off')\n",
    "    draw_bounding_box(row, img.shape[1], img.shape[0])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to draw bounding boxes\n",
    "def draw_bounding_box(row, img_width, img_height, rotation_angle=0, flip=False):\n",
    "    face_x, face_y, face_w, face_h = row['face_x'], row['face_y'], row['face_w'], row['face_h']\n",
    "    occluder_x, occluder_y, occluder_w, occluder_h = row['occluder_x'], row['occluder_y'], row['occluder_w'], row['occluder_h']\n",
    "    glasses_x, glasses_y, glasses_w, glasses_h = row['glasses_x'], row['glasses_y'], row['glasses_w'], row['glasses_h']\n",
    "    \n",
    "    # Adjust occluder coordinates relative to the face bounding box\n",
    "    occluder_x += face_x\n",
    "    occluder_y += face_y\n",
    "    \n",
    "    if rotation_angle != 0:\n",
    "        # Rotate bounding boxes\n",
    "        face_x, face_y = rotate_point(face_x, face_y, img_width / 2, img_height / 2, rotation_angle)\n",
    "        occluder_x, occluder_y = rotate_point(occluder_x, occluder_y, img_width / 2, img_height / 2, rotation_angle)\n",
    "        glasses_x, glasses_y = rotate_point(glasses_x, glasses_y, img_width / 2, img_height / 2, rotation_angle)\n",
    "    \n",
    "    if flip:\n",
    "        # Flip bounding boxes\n",
    "        face_x = img_width - face_x - face_w\n",
    "        occluder_x = img_width - occluder_x - occluder_w\n",
    "        glasses_x = img_width - glasses_x - glasses_w\n",
    "    \n",
    "    plt.gca().add_patch(patches.Rectangle((face_x, face_y), face_w, face_h, linewidth=2, edgecolor='r', facecolor='none'))\n",
    "    plt.gca().add_patch(patches.Rectangle((occluder_x, occluder_y), occluder_w, occluder_h, linewidth=2, edgecolor='b', facecolor='none'))\n",
    "    plt.gca().add_patch(patches.Rectangle((glasses_x, glasses_y), glasses_w, glasses_h, linewidth=2, edgecolor='g', facecolor='none'))\n",
    "\n",
    "\n",
    "# Function to rotate a point around an origin\n",
    "def rotate_point(x, y, cx, cy, angle):\n",
    "    angle_rad = np.deg2rad(angle)\n",
    "    x_new = (x - cx) * np.cos(angle_rad) - (y - cy) * np.sin(angle_rad) + cx\n",
    "    y_new = (x - cx) * np.sin(angle_rad) + (y - cy) * np.cos(angle_rad) + cy\n",
    "    return x_new, y_new\n",
    "\n",
    "# Testing the function\n",
    "# Assume `df` is your DataFrame containing image data\n",
    "row_index = 0  # Choose a specific row for testing\n",
    "row = df.iloc[row_index]\n",
    "augment_and_plot(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality Reduction PCA...Not sure what it does quite yet...\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "import os\n",
    "import logging\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "if not os.path.exists('logs'):\n",
    "    os.makedirs('logs')\n",
    "\n",
    "# Load the .mat file\n",
    "train_data = scipy.io.loadmat(r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\LabelTrainAll.mat')\n",
    "image_dir = r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\train-images'\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(train_data['label_train'][0])\n",
    "\n",
    "# Preprocess DataFrame to remove square brackets\n",
    "df['orgImgName'] = df['orgImgName'].apply(lambda x: x[0])\n",
    "df['imgName'] = df['imgName'].apply(lambda x: x[0])\n",
    "df['label'] = df['label'].apply(lambda x: ', '.join(map(str, x[0])))\n",
    "\n",
    "### Missing Value validation\n",
    "\n",
    "# Identify missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Fill in the missing values with the mean value.\n",
    "# df.fillna(df.mean(), inplace=True) # Cannot be done with images, thus we just remove the row completely.\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "### Validating the values column to ensure correct number of elements\n",
    "\n",
    "# Validate the number of elements in the 'label' column\n",
    "valid_label_count = df['label'].apply(lambda x: len(x.split(', ')) == 21)\n",
    "missing_values = valid_label_count.value_counts()[True]  # Count missing values\n",
    "print(\"\\nNumber of elements with expected label array size:\", missing_values)\n",
    "# print(\"Missing values:\", missing_values)\n",
    "\n",
    "### Double checking for duplicate values - Does nothing with them, just a note at the moment.\n",
    "\n",
    "logging.basicConfig(filename='logs\\duplicate_images.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def find_duplicate_images(image_dir):\n",
    "    \"\"\"\n",
    "    Find duplicate images in a directory based on their perceptual hashes and log them.\n",
    "    \"\"\"\n",
    "    # Dictionary to store hashes and corresponding filenames\n",
    "    hash_dict = {}\n",
    "    \n",
    "    # List to store duplicate image filenames\n",
    "    duplicate_images = []\n",
    "    \n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(image_dir):\n",
    "        # Check if the file is an image\n",
    "        if filename.endswith((\".jpg\", \".png\")):\n",
    "            # Get the full file path\n",
    "            filepath = os.path.join(image_dir, filename)\n",
    "            \n",
    "            # Open the image and calculate its hash\n",
    "            try:\n",
    "                with Image.open(filepath) as img:\n",
    "                    hash_val = str(imagehash.average_hash(img))\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing image {filename}: {e}\")\n",
    "                continue\n",
    "            \n",
    "            # Check if the hash already exists in the dictionary\n",
    "            if hash_val in hash_dict:\n",
    "                # Add the current filename and the filename already stored in hash_dict\n",
    "                duplicate_images.append((filename, hash_dict[hash_val]))\n",
    "                logging.info(f\"Duplicate image found: {filename} is a duplicate of {hash_dict[hash_val]}\")\n",
    "            else:\n",
    "                # Add the hash and filename to the dictionary\n",
    "                hash_dict[hash_val] = filename\n",
    "                \n",
    "    # Log the results\n",
    "    if duplicate_images:\n",
    "        logging.info(f\"Total {len(duplicate_images)} duplicate images found.\")\n",
    "    else:\n",
    "        logging.info(\"No duplicate images found.\")\n",
    "\n",
    "# Call the function to find and print duplicate images\n",
    "# find_duplicate_images(image_dir) # RE-ENABLE THIS IN ORDER TO FIND DUPLICATE IMAGES\n",
    "\n",
    "### Structure the data and convert into a csv\n",
    "\n",
    "# Extract bounding box information\n",
    "label_columns = ['face_x', 'face_y', 'face_w', 'face_h', 'eye1_x', 'eye1_y', 'eye2_x', 'eye2_y', 'occluder_x', 'occluder_y', 'occluder_w', 'occluder_h', 'occ_type', 'occ_degree', 'gender', 'race', 'orientation', 'glasses_x', 'glasses_y', 'glasses_w', 'glasses_h']\n",
    "df[label_columns] = df['label'].str.split(', ', expand=True)\n",
    "\n",
    "# Create separate columns for bounding boxes\n",
    "df['face_bbx'] = df.apply(lambda row: ', '.join(row[['face_x', 'face_y', 'face_w', 'face_h']].astype(str)), axis=1)\n",
    "df['left_eye_bbx'] = df.apply(lambda row: ', '.join(row[['eye1_x', 'eye1_y']].astype(str)), axis=1)\n",
    "df['right_eye_bbx'] = df.apply(lambda row: ', '.join(row[['eye2_x', 'eye2_y']].astype(str)), axis=1)\n",
    "df['occluder_bbx'] = df.apply(lambda row: ', '.join(row[['occluder_x', 'occluder_y', 'occluder_w', 'occluder_h']].astype(str)), axis=1)\n",
    "df['occluder_type'] = df['occ_type']\n",
    "df['occluder_degree'] = df['occ_degree']\n",
    "# df['face_gender'] = df['gender'] # Removing these columns is a form of dimensionality reduction\n",
    "# df['face_race'] = df['race']\n",
    "# df['face_orientation'] = df['orientation']\n",
    "df['glasses_bbx'] = df.apply(lambda row: ', '.join(row[['glasses_x', 'glasses_y', 'glasses_w', 'glasses_h']].astype(str)), axis=1)\n",
    "\n",
    "# Drop the original columns\n",
    "df.drop(columns=label_columns, inplace=True)\n",
    "\n",
    "# Convert the extracted columns to numeric type\n",
    "df[['face_bbx', 'left_eye_bbx', 'right_eye_bbx', 'occluder_bbx', 'occluder_type', 'occluder_degree', 'glasses_bbx']] = df[['face_bbx', 'left_eye_bbx', 'right_eye_bbx', 'occluder_bbx', 'occluder_type', 'occluder_degree', 'glasses_bbx']].apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "\n",
    "# Drop the original 'label' column\n",
    "df.drop(columns=['label'], inplace=True)\n",
    "\n",
    "# Exclude non-numeric columns from DataFrame before standardization\n",
    "non_numeric_columns = ['orgImgName', 'imgName']\n",
    "numeric_columns = [col for col in df.columns if col not in non_numeric_columns]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df[numeric_columns])\n",
    "\n",
    "# Impute missing values with the mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = imputer.fit_transform(df_scaled)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=0.5)  # Keep 95% of variance\n",
    "df_pca = pca.fit_transform(df_imputed)\n",
    "\n",
    "# Convert PCA results back to DataFrame\n",
    "df_pca = pd.DataFrame(df_pca, columns=[f'PC{i+1}' for i in range(df_pca.shape[1])])\n",
    "\n",
    "# Save the DataFrame to a CSV file without square brackets\n",
    "df_pca.to_csv('csv/MAFA_Label_Train_PCA.csv', index=False)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(\"\\nDataFrame after PCA:\")\n",
    "print(df_pca.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puts the train data (unstructured) into a csv in order to apply dimensionality reduction on it.\n",
    "\n",
    "# Load the .mat file\n",
    "train_data = scipy.io.loadmat(r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\LabelTrainAll.mat')\n",
    "image_dir = r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\train-images'\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(train_data['label_train'][0])\n",
    "\n",
    "# Preprocess DataFrame to remove square brackets\n",
    "df['orgImgName'] = df['orgImgName'].apply(lambda x: x[0])\n",
    "df['imgName'] = df['imgName'].apply(lambda x: x[0])\n",
    "df['label'] = df['label'].apply(lambda x: ', '.join(map(str, x[0])))\n",
    "\n",
    "# Structure the data\n",
    "label_columns = ['face_x', 'face_y', 'face_w', 'face_h', 'eye1_x', 'eye1_y', 'eye2_x', 'eye2_y', \n",
    "                 'occluder_x', 'occluder_y', 'occluder_w', 'occluder_h', 'occluder_type', 'occluder_degree', \n",
    "                 'gender', 'race', 'orientation', 'glasses_x', 'glasses_y', 'glasses_w', 'glasses_h']\n",
    "df[label_columns] = df['label'].str.split(', ', expand=True)\n",
    "\n",
    "# Convert the bounding box coordinates from strings to floats\n",
    "for col in label_columns:\n",
    "    df[col] = df[col].astype(float)\n",
    "\n",
    "df.drop(columns=['label'], inplace=True)\n",
    "\n",
    "# Define columns for the CSV\n",
    "csv_columns = ['orgImgName', 'imgName', 'face_x', 'face_y', 'face_w', 'face_h', \n",
    "               'eye1_x', 'eye1_y', 'eye2_x', 'eye2_y', 'occluder_x', 'occluder_y', 'occluder_w', 'occluder_h', 'occluder_type', 'occluder_degree',\n",
    "               'gender', 'race', 'orientation', 'glasses_x', 'glasses_y', 'glasses_w', 'glasses_h']\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df[csv_columns].to_csv('csv/MAFA_training_data_unstructured.csv', index=False)\n",
    "\n",
    "print(\"CSV file has been successfully generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA - Linear Discriminant Analysis - Dimensionality Reduction \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University_Programming\\Python\\Big_Data\\Coursework\\Masked_Face\\csv\\MAFA_Label_Train.csv')\n",
    "\n",
    "# Drop irrelevant features\n",
    "df.drop(columns=['orgImgName', 'imgName', 'glasses_bbx'], inplace=True)\n",
    "\n",
    "# Filter out occluder_type equal to 3\n",
    "df = df[df['occluder_type'].isin([1, 2])]\n",
    "\n",
    "# Convert string features to numeric\n",
    "df[['face_bbx', 'left_eye_bbx', 'right_eye_bbx', 'occluder_bbx']] = df[['face_bbx', 'left_eye_bbx', 'right_eye_bbx', 'occluder_bbx']].apply(lambda x: x.str.split(',').apply(lambda y: [float(val) for val in y]))\n",
    "\n",
    "# Expand the columns containing lists into separate columns\n",
    "df = pd.concat([df.drop(columns=['face_bbx', 'left_eye_bbx', 'right_eye_bbx', 'occluder_bbx']), df['face_bbx'].apply(pd.Series).add_suffix('_face'), df['left_eye_bbx'].apply(pd.Series).add_suffix('_left_eye'), df['right_eye_bbx'].apply(pd.Series).add_suffix('_right_eye'), df['occluder_bbx'].apply(pd.Series).add_suffix('_occluder')], axis=1)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=['occluder_type'])\n",
    "y = df['occluder_type']\n",
    "\n",
    "# Initialize and fit LDA with reduced number of components\n",
    "n_classes = len(y.unique())\n",
    "n_features = X.shape[1]\n",
    "n_components = min(n_features, n_classes - 1)  # Ensure valid number of components\n",
    "lda = LinearDiscriminantAnalysis(n_components=n_components)\n",
    "X_lda = lda.fit_transform(X, y)\n",
    "\n",
    "# Create a DataFrame for the transformed data\n",
    "df_lda = pd.DataFrame(data=X_lda, columns=[f'LD{i}' for i in range(1, n_components + 1)])\n",
    "\n",
    "# Concatenate the transformed data with the target variable\n",
    "df_lda['occluder_type'] = y.reset_index(drop=True)\n",
    "\n",
    "# Save the transformed data to a new CSV file\n",
    "df_lda.to_csv('csv\\lda_transformed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the LDA results\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "df_lda = pd.read_csv('csv\\lda_transformed_data.csv')\n",
    "\n",
    "# Separate data points for each class\n",
    "class1 = df_lda[df_lda['occluder_type'] == 1.0]\n",
    "class2 = df_lda[df_lda['occluder_type'] == 2.0]\n",
    "\n",
    "# Plot the data points for each class\n",
    "plt.scatter(class1['LD1'], [1] * len(class1), label='occluder_type 1.0', color='blue')\n",
    "plt.scatter(class2['LD1'], [2] * len(class2), label='occluder_type 2.0', color='red')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('LD1')\n",
    "plt.yticks([1, 2], ['occluder_type 1.0', 'occluder_type 2.0'])\n",
    "plt.title('Scatter Plot of LD1 vs occluder_type')\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 2 to at logistic regression model: https://www.justintodata.com/logistic-regression-example-in-python/\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, roc_auc_score, recall_score, precision_score, average_precision_score, f1_score, classification_report, accuracy_score\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "train_data_path = r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\LabelTrainAll.mat'\n",
    "\n",
    "### Explore and clean the data ###\n",
    "\n",
    "# Read the lines from the text file\n",
    "with open(train_data_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Initialize lists to store data\n",
    "image_paths = []\n",
    "num_faces_list = []\n",
    "face_info_list = []\n",
    "\n",
    "# Process lines to extract information\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "\n",
    "    # Skip empty lines\n",
    "    if not line:\n",
    "        continue\n",
    "\n",
    "    # Check if it represents an image path\n",
    "    if line.endswith('.jpg'):\n",
    "        image_paths.append(line)\n",
    "        # Initialize num_faces and face_info\n",
    "        num_faces = None\n",
    "        face_info = []\n",
    "    else:\n",
    "        # If it's not an image path, it's face information\n",
    "        if num_faces is None:\n",
    "            # Extract the number of faces\n",
    "            num_faces = int(line)\n",
    "        else:\n",
    "            # Split face information\n",
    "            face_info.extend([int(x) for x in line.split()])\n",
    "\n",
    "        # Check if we have collected enough face information\n",
    "        if len(face_info) == num_faces * 10:\n",
    "            num_faces_list.append(num_faces)\n",
    "            face_info_list.append(face_info)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Image_Path': image_paths,\n",
    "    'Num_Faces': num_faces_list,\n",
    "    'Face_Info': face_info_list\n",
    "})\n",
    "\n",
    "# Prints the column names of the DataFrame\n",
    "# df.columns # OUTPUT: Index(['Image_Path', 'Num_Faces', 'Face_Info'], dtype='object')\n",
    "\n",
    "# Display the DataFrame\n",
    "# print(df.head())\n",
    "\n",
    "# This code can be used to find out how many pictures have 1 face, how many have 2 faces...singles out one of the data types\n",
    "# df = df.rename(columns={'Num_Faces': 'target'})\n",
    "# df['target'].value_counts(dropna=False)\n",
    "\n",
    "# Lists a summary of the dataframe\n",
    "# df.info()\n",
    "\n",
    "# If df.info() returns columns with wildly different values, the below code will remove the ones with many missing values\n",
    "# df = df.drop(['slope', 'ca', 'thal'], axis=1) # slope, ca, and thal were values from the example\n",
    "# df = df.dropna().copy()\n",
    "\n",
    "# Nice summary of the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Load the .mat file\n",
    "mat_data = scipy.io.loadmat(r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\MAFA-Label-Train\\LabelTrainAll.mat')\n",
    "\n",
    "# Extract the labels\n",
    "label_data = mat_data['label_train'][0]\n",
    "\n",
    "# Assuming you know the image file names, you can list them from the train_images directory\n",
    "image_files_path = r'C:\\Users\\alexw\\OneDrive\\Documents\\03_Education\\University\\University_Programming\\Python\\Big_Data\\Coursework\\Datasets\\MAFA\\train-images\\images'\n",
    "image_files = os.listdir(image_files_path)\n",
    "\n",
    "# Ensure num_samples is not greater than the number of available images and labels\n",
    "num_samples = min(5, len(image_files), len(label_data))  # Number of sample images to display\n",
    "\n",
    "# Randomly select indices for sampling\n",
    "random_indices = np.random.choice(len(image_files), num_samples, replace=False)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, random_idx in enumerate(random_indices, 1):\n",
    "    image_file = image_files[random_idx]\n",
    "    image_path = os.path.join(image_files_path, image_file)\n",
    "    image = plt.imread(image_path)\n",
    "    plt.subplot(1, num_samples, i)\n",
    "    plt.imshow(image)\n",
    "    \n",
    "    # Extract labels for the current image\n",
    "    org_img_name = label_data[random_idx][0][0]\n",
    "    img_name = label_data[random_idx][1][0]\n",
    "    label = label_data[random_idx][2][0]\n",
    "    \n",
    "    # Get the face bounding box\n",
    "    face_bbox = label[:4]\n",
    "    x, y, w, h = face_bbox\n",
    "    \n",
    "    # Draw face bounding box\n",
    "    plt.gca().add_patch(patches.Rectangle((x, y), w, h, linewidth=2, edgecolor='r', facecolor='none'))\n",
    "    \n",
    "    # Get the bounding box of the occluder\n",
    "    occluder_bbox = label[8:12]\n",
    "    if any(occluder_bbox != -1):\n",
    "        ox, oy, ow, oh = occluder_bbox\n",
    "        # Draw occluder bounding box\n",
    "        plt.gca().add_patch(patches.Rectangle((x + ox, y + oy), ow, oh, linewidth=2, edgecolor='b', facecolor='none'))\n",
    "    \n",
    "    # Get the bounding box of the glasses\n",
    "    glasses_bbox = label[-4:]\n",
    "    if any(glasses_bbox != -1):\n",
    "        gx, gy, gw, gh = glasses_bbox\n",
    "        # Draw glasses bounding box\n",
    "        plt.gca().add_patch(patches.Rectangle((x + gx, y + gy), gw, gh, linewidth=2, edgecolor='g', facecolor='none'))\n",
    "    \n",
    "    # Determine whether the person is wearing a mask or not\n",
    "    occ_type = label[12]\n",
    "    plt.title('Mask' if occ_type == 1 else 'No Mask')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
